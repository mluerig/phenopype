{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Measuring shape, size and colour of isopods  \n",
    "\n",
    "In this example I am demonstrating low and high throughput workflow in phenopype by decomposing the all the required steps for a classic computer vision workflow. \n",
    "\n",
    "Little nugget of information: this was the original computer vision problem that phenopype was intended to solve (it's predecessor [\"iso_cv\"](https://github.com/mluerig/iso_cv) was not much more than a script-collection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "    \n",
    "**Related tutorials, examples and further reading**\n",
    "\n",
    "<ul>\n",
    "<li><a href=\"tutorial_2_phenopype_images.ipynb\">Tutorial 2: Interacting with images in phenopype</a></li>\n",
    "<li><a href=\"tutorial_3_phenopype_workflows.ipynb\">Tutorial 3: The three phenopype workflows</a></li>\n",
    "<li><a href=\"resources.html#computer-vision\">About the structure of digital images</a></li>\n",
    "<li><a href=\"https://docs.opencv.org/3.4.9/d9/d61/tutorial_py_morphological_ops.html\">About morphological operations</a></li>\n",
    "</ul>\n",
    "       \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"row; text-align: left\">\n",
    "    \n",
    "<div class=\"col-md-6\">\n",
    "    \n",
    "![Before](_assets/ex1_before.jpg)\n",
    "    \n",
    "**Input** - Freshwater isopod, alive, photographed on a white resin-tray from a camera stand. \n",
    "</div>\n",
    "<div class=\"col-md-6\">\n",
    "\n",
    "![After](_assets/ex1_after.jpg)\n",
    "    \n",
    "**Results** - Isopod shape, size and colour are extracted (and size referenced using the reference card) \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the image\n",
    "\n",
    "First we import the image from the a filepath using `load_image`. With the flag `df=True` we can extract some image-meta information that we want to be represented in the results files later (i.e. image name and its dimensions). After loading it, we can have a quick look at it with the `show_image` function - you can close it again with `Enter` or `Esc`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = r\"images/isopods.jpg\"\n",
    "image, img_data = pp.load_image(filepath, \n",
    "                                df=True)\n",
    "pp.show_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drawing a mask\n",
    "\n",
    "The original image has a lot of noise, e.g. the non-white area around the tray, water reflections, the label, the reference card, and the little fecal pellets that lie around on the tray. Classic computer vision algorithms are unspecific to the object, so they will pick up any object that is darker than its environment. Therefore, a useful preprocessing step is to exclude some of that noise by applying a mask. With the `create_mask` function, you can include or exclude certain areas of the image from the following analysis steps (`include=True/False`). \n",
    "\n",
    "Here, we want to include all of the wite tray that has isopods in it: Hold the left button down and drag the rectangle shaped mask tool over the area you want to include.\n",
    "\n",
    "<center>\n",
    "<div style=\"width:500px; text-align: left\" >\n",
    "    \n",
    "![Create masks](_assets/masks1.gif)\n",
    "\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- creating mask\n"
     ]
    }
   ],
   "source": [
    "df_masks = pp.preprocessing.create_mask(image,\n",
    "                                        df_image_data=img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create size reference\n",
    "\n",
    "Within the area we masked lies the reference card. We want to include its information in our results files (the pixel-to-mm-ratio), so we supply the image meta DataFrame with `df_image_data=img_data`. However, we do not want the card itself to be detected, so we mask it with the argument `mask=True` and by supplying or mask DataFrame with `df_masks=df_masks` to have both masks in one place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:500px; text-align: left\">\n",
    "    \n",
    "![Adding a scale](_assets/ex1_scale.gif)\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- measure pixel-to-mm-ratio\n",
      "Reference set\n",
      "- add column length\n",
      "Template selected\n",
      "Template selected\n"
     ]
    }
   ],
   "source": [
    "img_data, df_masks = pp.preprocessing.create_reference(image, \n",
    "                                                       mask=True,\n",
    "                                                       df_image_data=img_data, \n",
    "                                                       df_masks=df_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `df_masks` DataFrame contains two masks: the one we created above that *includes* the tray and the one we made to *exclude* the scale reference card:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coords</th>\n",
       "      <th>filename</th>\n",
       "      <th>height</th>\n",
       "      <th>include</th>\n",
       "      <th>mask</th>\n",
       "      <th>width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(239, 166), (1887, 166), (1887, 1349), (239, ...</td>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>mask1</td>\n",
       "      <td>2100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(446, 1028), (674, 1028), (674, 1223), (446, ...</td>\n",
       "      <td>isopods.jpg</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>reference</td>\n",
       "      <td>2100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              coords     filename  height  \\\n",
       "0  [(239, 166), (1887, 166), (1887, 1349), (239, ...  isopods.jpg  1400.0   \n",
       "0  [(446, 1028), (674, 1028), (674, 1223), (446, ...  isopods.jpg  1400.0   \n",
       "\n",
       "   include       mask   width  \n",
       "0      1.0      mask1  2100.0  \n",
       "0      0.0  reference  2100.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masks "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now have a quick look at both masks together by calling the visualization function `draw_mask`, followed by `show_image`. For this we should create a new array and *not* overwrite the original image loaded before - here we call it `canvas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drawing mask: mask1\n",
      "drawing mask: reference\n"
     ]
    }
   ],
   "source": [
    "canvas = pp.visualization.draw_masks(image, \n",
    "                                     df_masks=df_masks, \n",
    "                                     line_width=3)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - 1st attempt\n",
    "\n",
    "Now that we have removed most of the noise, we can implement an algorithm that segments the imgae into foreground and background (check the [resources section](resources.html#computer-vision) of the documentation. Here we use the `threshold` algorithm that to detect the isopods as foreground and the tray as background. By supplying the mask DataFrame we created before with `df_masks=masks`, we can exclude the unwanted regions of the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- excluding pixels from 1 drawn masks \n",
      "- including pixels from 1 drawn masks \n"
     ]
    }
   ],
   "source": [
    "image_bin = pp.segmentation.threshold(image, df_masks=df_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting array `image_bin` is a binary image where white regions are foreground and black background:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, but there is still a lot of noise inside the image (isopod fecal pellets) that we need to remove. Right now, all information about foreground and background is in \"pixel-space\", i.e. it's a drawn representation of the informative areas. To convert it to coordinate space, and in the later steps extract information from the raw image, we will use `find_contours` on this binary image. But setting the argument `min_area`, we can set a minimum size for the area that the contours should have - 100 pixels should be enough to exclude all fecal pellets. Again, we can supply the image meta DataFrame to concatenate existing information. Afterwards we can draw the contours onto `canvas` with `draw_contours` - the detected contours are in green. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- found 20 contours that match criteria\n"
     ]
    }
   ],
   "source": [
    "df_contours = pp.segmentation.find_contours(image_bin, df_image_data=img_data, min_area=100) \n",
    "canvas = pp.visualization.draw_contours(canvas, df_contours=df_contours)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - 2nd attempt\n",
    "\n",
    "Now we have excluded all noise - but some isopods are not well deteced. Mostly the ones with lighter pigmenation, because the contrast they form agains the light background isn't strong enough. We can try a different threshold algorithm by setting the `method` argument: `\"adaptive\"` algorithms work particularly well with variable contrast levels and lighting. \n",
    "\n",
    "Additionally, instead of using the default gray channel (i.e. the average across all three colour channels), we can try to run the thresholding function on a single colour channel. The contrast and signal-to-noise-ratio can be different betweeen the channels. We can select a different channel using the `select_canvas` function - here I isolate all three colour channels, and supply them to `show_image` to show themm all at once, and to evaluate, which colour-channels is suited best: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- red channel\n",
      "- green channel\n",
      "- blue channel\n"
     ]
    }
   ],
   "source": [
    "r = pp.visualization.select_canvas(image, \n",
    "                                   canvas=\"r\")\n",
    "g = pp.visualization.select_canvas(image, \n",
    "                                   canvas=\"g\")\n",
    "b = pp.visualization.select_canvas(image, \n",
    "                                   canvas=\"b\")\n",
    "pp.show_image([r,g,b], max_dim=500) ## max_dim=reduce window size to 500 pixels on any axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at this suggests that the green colour channel will yield the best results: here, even the lighter pigmented isopods have a strong contrast against the tray. We can supply either `g` to `threshold`, or directly select this with the `channel` argument:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- excluding pixels from 1 drawn masks \n",
      "- including pixels from 1 drawn masks \n"
     ]
    }
   ],
   "source": [
    "image_bin = pp.segmentation.threshold(image, method=\"adaptive\", df_masks=df_masks, channel=\"green\")\n",
    "pp.show_image(image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - 3rd attempt\n",
    "\n",
    "Obviously we need to to tune a few things here, way to many things are being detected. Currently the `\"adaptive\"` algorithm is on default sensitivity (`blocksize=99`), which we can reduce a bit. Also, we can increase the value for the constant to be subtracted after the tresholding with `constant`. We will try `blocksize=49` and `constant=5`. Afterwards, we plot the detected contours back onto the canvas of the original image, not the green channel image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:800px; text-align: left\">\n",
    "\n",
    "![Binarization](_assets/ex1_binarization.jpg)\n",
    "        \n",
    "**Figure 2** - Demonstration of blocksize (19, 99, 199 - left to right) and constant (1, 5 - top and bottom) parameters. Increasing blocksize leads to better structuring of the pixel level information contained in the image (i.e. larger \"blocks\" of connected pixels can be detected). This is computationally costly, so it will be slow for large images. Also, there is an optimal value beyond which detection performance will decrease. \n",
    "\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- excluding pixels from 1 drawn masks \n",
      "- including pixels from 1 drawn masks \n",
      "- found 22 contours that match criteria\n"
     ]
    }
   ],
   "source": [
    "image_bin = pp.segmentation.threshold(image, \n",
    "                                      method=\"adaptive\", \n",
    "                                      blocksize=49, \n",
    "                                      constant=5, \n",
    "                                      df_masks=df_masks, \n",
    "                                      channel=\"green\")\n",
    "df_contours = pp.segmentation.find_contours(image_bin, \n",
    "                                            df_image_data=img_data, \n",
    "                                            min_area=100)\n",
    "canvas = pp.visualization.draw_contours(image, \n",
    "                                        df_contours=df_contours, \n",
    "                                        line_width=1)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation - final product\n",
    "\n",
    "That looks pretty good. The last thing we need to take care of are the appendages (we don't want to include those) and the gaps that sometimes form between the segments (we want to have that error to be consistent towards no gaps). Some blurring, and a morphological operation will do the trick. Blurring will smooth the contour of the isopods, and a farly large `\"cross\"` shaped kernel will \"cut off\" the appendages and other long structures in the binary image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- excluding pixels from 1 drawn masks \n",
      "- including pixels from 1 drawn masks \n",
      "- found 20 contours that match criteria\n",
      "drawing mask: mask1\n",
      "drawing mask: reference\n"
     ]
    }
   ],
   "source": [
    "image_blurred = pp.segmentation.blur(image, \n",
    "                                     kernel_size = 15)\n",
    "image_bin = pp.segmentation.threshold(image_blurred, \n",
    "                                      method=\"adaptive\", \n",
    "                                      blocksize=49, \n",
    "                                      constant=5, \n",
    "                                      df_masks=df_masks,  \n",
    "                                      channel=\"green\")\n",
    "image_morph = pp.segmentation.morphology(image_bin, \n",
    "                                         operation=\"open\", \n",
    "                                         shape=\"cross\", \n",
    "                                         kernel_size = 9, \n",
    "                                         iterations=2)\n",
    "\n",
    "contours = pp.segmentation.find_contours(image_morph, \n",
    "                                         df_image_data=img_data, \n",
    "                                         min_area=250)\n",
    "canvas = pp.visualization.draw_masks(image, \n",
    "                                     df_masks=df_masks, \n",
    "                                     line_width=3)\n",
    "canvas = pp.visualization.draw_contours(canvas, \n",
    "                                        df_contours=contours, \n",
    "                                        line_width=1)\n",
    "pp.show_image(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring colour\n",
    "\n",
    "Ok, this looks good - we now have a DataFrame with the contour-data of all 20 isopods, including their length (`diameter` of the enclosing circle), and the shape (`coords`). Using this information, we can finally extract the colour information from inside the contours. To do so we can supply the original image array along with the contour DataFrame to the `colour_intensity` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pigmentation = pp.measurement.colour_intensity(image, \n",
    "                                               df_image_data=img_data, \n",
    "                                               df_contours=contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export\n",
    "\n",
    "Done - we can now save the contours and the colour information to csv, as well as the canvas for quality control:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- contours saved under _temp/output/ex1\\contours.csv (overwritten).\n",
      "- colours saved under _temp/output/ex1\\colours.csv (overwritten).\n",
      "- canvas saved under _temp/output/ex1\\canvas.jpg (overwritten).\n"
     ]
    }
   ],
   "source": [
    "pp.export.save_contours(contours, \n",
    "                        dirpath=r\"_temp/output/ex1\")\n",
    "pp.export.save_colours(pigmentation, \n",
    "                       dirpath=r\"_temp/output/ex1\")\n",
    "pp.export.save_canvas(canvas, \n",
    "                      dirpath=r\"_temp/output/ex1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High throughput\n",
    "\n",
    "Now we will use the `pype` method to detect the isopods. For more information on how to analyze multiple images and whole datasets with this approach, check [Tutorial 3](tutorial_3_phenopype_workflow.ipynb).\n",
    "\n",
    "<center>\n",
    "<div style=\"width:600px; text-align: left\" >\n",
    "    \n",
    "![Phenopype high throughput workflow](_assets/workflow_high.png)\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, the appropriate settings for this example are contained in a template named `ex1`, which we can supply directly to the `pype`. Note that we need to rename this run, otherwise the `pype` will reload our old settings (you can also just delete them in the folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'demo.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\demo.yaml',\n",
       " 'ex1.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex1.yaml',\n",
       " 'ex2.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex2.yaml',\n",
       " 'ex3.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex3.yaml',\n",
       " 'ex5_1.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex5_1.yaml',\n",
       " 'ex5_2.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex5_2.yaml',\n",
       " 'ex6.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex6.yaml',\n",
       " 'ex7.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex7.yaml',\n",
       " 'ex8_1.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex8_1.yaml',\n",
       " 'ex8_2.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\ex8_2.yaml',\n",
       " 'landmarks1.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\landmarks1.yaml',\n",
       " 'landmarks2.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\landmarks2.yaml',\n",
       " 'tut3.yaml': 'd:\\\\workspace\\\\git\\\\phenopype\\\\phenopype\\\\templates\\\\tut3.yaml'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.pype_config_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOWING BUILTIN PHENOPYPE TEMPLATE ex1.yaml\n",
      "\n",
      "\n",
      "- preprocessing:\n",
      "  - create_mask\n",
      "  - create_reference:\n",
      "      mask: true\n",
      "- segmentation:\n",
      "  - blur:\n",
      "      kernel_size: 15\n",
      "  - threshold:\n",
      "      method: adaptive\n",
      "      blocksize: 49\n",
      "      constant: 5\n",
      "      channel: green\n",
      "  - morphology:\n",
      "      operation: open\n",
      "      shape: cross\n",
      "      kernel_size: 9\n",
      "      iterations: 2\n",
      "  - find_contours:\n",
      "      retrieval: ccomp\n",
      "      min_diameter: 0\n",
      "      min_area: 250\n",
      "- visualization:\n",
      "  - select_canvas:\n",
      "      canvas: image\n",
      "  - draw_contours:\n",
      "      line_width: 2\n",
      "      label_width: 1\n",
      "      label_size: 1\n",
      "      fill: 0.3\n",
      "- export:\n",
      "  - save_contours:\n",
      "      overwrite: true\n"
     ]
    }
   ],
   "source": [
    "pp.show_config_template(\"ex1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory to save phenopype-container output set to parent folder of image:\n",
      "D:\\workspace\\git\\phenopype\\tutorials\\images\n",
      "pype_config_iso2.yaml already exists - overwrite?\n",
      "y: yes, file will be overwritten and loaded\n",
      "n: no, existing file will be loaded instead\n",
      "To load an existing file, use \"config\" instead of \"template\".y\n",
      "New pype configuration created (ex1.yaml) from phenopype template:\n",
      "d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex1.yaml\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2021:05:10 15:28:18 +++--------------\n",
      "\n",
      "\n",
      "=== AUTOLOAD ===\n",
      "- masks_iso2.csv\n",
      "PREPROCESSING\n",
      "create_mask\n",
      "- mask with label mask1 already created (edit/overwrite=False)\n",
      "create_reference\n",
      "- measure pixel-to-mm-ratio\n",
      "Reference set\n",
      "- add column length\n",
      "Template selected\n",
      "- reference template mask already created (overwrite=False)\n",
      "SEGMENTATION\n",
      "blur\n",
      "threshold\n",
      "- excluding pixels from 1 drawn masks \n",
      "- including pixels from 1 drawn masks \n",
      "morphology\n",
      "find_contours\n",
      "- found 20 contours that match criteria\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- invalid selection - defaulting to raw image\n",
      "draw_contours\n",
      "EXPORT\n",
      "save_contours\n",
      "- contours saved under _temp/output/ex1\\contours_iso2.csv (overwritten).\n",
      "=== AUTOSAVE ===\n",
      "save_canvas\n",
      "- canvas saved under _temp/output/ex1\\canvas_iso2.jpg (overwritten).\n",
      "save_masks\n",
      "- masks saved under _temp/output/ex1\\masks_iso2.csv (overwritten).\n",
      "\n",
      "\n",
      "------------+++ finished pype iteration +++--------------\n",
      "-------(End with Ctrl+Enter or re-run with Enter)--------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phenopype.main.pype at 0x2891ae2ebc8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.pype(filepath, \n",
    "        name=\"iso2\", \n",
    "        template=\"ex1\", \n",
    "        dirpath=r\"_temp/output/ex1\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
