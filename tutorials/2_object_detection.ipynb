{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\git_repos\\phenopype\\phenopype\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "#%% DEV_startup\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import trackpy as tp\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy.ma as ma\n",
    "\n",
    "os.chdir(\"E:\\\\git_repos\\\\phenopype\")\n",
    "\n",
    "import phenopype as pp\n",
    "from importlib import reload\n",
    "reload(pp)\n",
    "print(pp.__file__)\n",
    "\n",
    "self = type('dummy_self', (object,), {})()\n",
    "kwargs = dict()\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: object detection\n",
    "\n",
    "This example demonstrates basic `phenopype` functionality by showing how multiple objects can be found and extracted from images via thresholding. The images used for this tutorial contain isopods sitting inside a white tray underneath a camera stand, photopgraphed with a 50 mm lens on a Canon 750D. \n",
    "***\n",
    "* [collect images](#collect)\n",
    "* [set a scale](#scale)\n",
    "* [object finder - single object](#object1)\n",
    "* [mask images](#mask)\n",
    "* [object finder - multiple objects](#object2)\n",
    "* [object finder - multiple files](#object3)\n",
    "* [object finder - variable background](#object4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import phenopype as pp\n",
    "\n",
    "# for this tutorial, you should be in the \"tutorial directory of phenopype-master\"\n",
    "#os.getcwd()\n",
    "#os.chdir(\"tutorials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# collect images<a name=\"collect\"></a>\n",
    "\n",
    "Start by loading the program. We can use `import as` with shorter bindings, so we can type `pp` instead of `phenopype` everytime we call a function. Next we specificy the folder containing the images, making a project object that contains all the image names and paths. The function `project_maker` will then collect all files that match your specifications (filetypes or names). \n",
    "\n",
    "For this first simple example, we only want to include the image named \"bug1.jpg\". We can do so using `include` (or, `exclude` to skip images whose filenames contain this string). Note that this can be any sub-string and does not have to be the whole filename, so in this case \"bug1\" will suffice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a quick look at the image using the collected absolute filepaths (accessible from the `my_proj` object) and the _phenopye_ function `show_img` (contains all the `opencv` GUI controls explained in  [tutorial 1](1_python_intro.ipynb#images). Close the image by hitting enter or closing the window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_proj = pp.project_maker(image_dir = \"images\", include=[\"bug1\"]) \n",
    " \n",
    "# HINT: image_dir can be relative or absolute \n",
    "# e.g. something like \"your_download_directory//phenopype-master//tutorials//images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = my_proj.filepaths[0] \n",
    "pp.show_img(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setting a scale <a name=\"scale\"></a>\n",
    "-|-\n",
    "-|-\n",
    "![](../assets/tutorials/make_scale.gif)|![](../assets/tutorials/scale.png)\n",
    "\n",
    "Our image contains and organism, and a scale. To make our measurements meaningful, we need to know the the pixel to mm ratio. To do so we we load the image into the `scale_maker`, `zoom` into the scale area for better visibility, and mark the distance we specifiy - in this case 10 mm. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scale = pp.scale_maker(image=img_path, value=10, unit=\"mm\",  zoom=True, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the scale by calling its variable `measured`, which always will give you the ratio of **pixels per 1 mm**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scale.measured, \" # pixel per mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object finder <a name=\"object-finder\"></a>\n",
    "\n",
    "Finding objects inside an image is a core function of _phenopype_. Results depend on how \"good\" your pictures are with respect to foreground contrast of your objects, homogeneity of your background, and overall illumination and resoution. The pictures we have loaded above are pretty good for that purpose. However, don't give up just now if your images have less ideal contrast or a noisy background. _phenopype_ comes with a flavor of different preprossing strategies and well established thresholding algorithms in [opencv](https://docs.opencv.org/3.4/d7/d4d/tutorial_py_thresholding.html), wrapped in a simple method: the `object_finder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(pp.object_finder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`object_finder` is a [class](https://docs.python.org/3.7/tutorial/classes.html), that means we have to initialize it first, and then run the actual [method](https://stackoverflow.com/questions/20981789/difference-between-methods-and-functions-in-python-compared-to-c). After initializing it with our image, we can find objects using `find_objects`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = pp.object_finder(image=img_path)\n",
    "results = of.find_objects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### masking images <a name=\"mask\"></a>\n",
    "\n",
    "Ok, this is not right - we need to only include our organism in our image by applying a mask to be included. This we can do with the function called `polygon_maker` and the argument `include=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pp.polygon_maker(img_path)\n",
    "mask1 = mask.draw(mode=\"rectangle\", show=True, include=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mask can the be passed on the the `object_finder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = of.find_objects(mask=[mask1]) # NOTE: your mask should be inside a list -> []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next problem is, that our organism is being recognized as many small objects. If we only have one organism in our image, we can swith to the `mode` \"single\". Also, we want to disregard legs and antenna. The removal of small structures can be accomplished by adding some gaussian noise to the image with the `blur1` variable (`blur1` = first pass blurring, `blur2` = second pass blurring). The provided number of the size of your blur kernel in pixels (bigger = more blurred). At this point we should also include the scale we measured earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = of.find_objects(mask=[mask1], mode=\"single\", blur1=25, scale=scale.measured) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we see in the console is just for evalution and does not show us much information. To see at what we actually measured, let's look at the `results` object, which contains some metadata, and the phenotypic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Variable|Description\n",
    "-|-\n",
    "filename | name of the image file\n",
    "date_taken | timestamp of when your image was taken. (y-m-d h-m-s), or NA\n",
    "date_analyzed | timestamp of when your image was analyzed (i.e., current time). (y-m-d h-m-s)\n",
    "idx | if you have multiple objects in your image, this will correspond to the labels\n",
    "resize_factor | sometimes it is necessary to resize large images. this keeps track of it \n",
    "scale | the provided scale, number of pixels per 1 mm\n",
    "diameter | from the bounding circle of our object\n",
    "area | inside the contour of our object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can measure aditional parameters that we pass on using the `operations` argument - e.g. \"bgr\", which returns the mean values for blue, green, and red pixels (for a full list of operations, see `help(pp.object_finder)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = of.find_objects(mask=[mask1], mode=\"single\", blur1=25, scale=scale.measured, operations = [\"grayscale\", \"bgr\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can keep running the `find_objects` method until we are happy with our results. Once that is the case, we save both the results data frame using `save_csv`; and the processed image, which we get by accessing `image_processed` in the `object_finder` object, and saving it with `save_img`. As name we use the filename that we get from the `my_proj` object.\n",
    "\n",
    "Note that by default, text files and images are overwritten if they already exists in the specified directory. Also, if a directory does not exists, it will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = my_proj.filenames[0]\n",
    "\n",
    "pp.save_csv(df=results, name=img_name, save_dir=\"images_out\")\n",
    "pp.save_img(image=of.image_processed, name=img_name, save_dir=\"images_out\", resize=0.25)\n",
    "# NOTE: you can resize images with the \"resize\" argument to save space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now should be able to handle the `object_finder` class. Below I will introduce more examples and processing steps that can improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object finder - multiple objects <a name=\"object2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will load a different set of images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_proj = pp.project_maker(image_dir = \"images\", include=[\"multiple\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = my_proj.filepaths[0] # we only use the first image\n",
    "scale = pp.scale_maker(image=img_path, value=10, unit=\"mm\",  zoom=True, show=True) # measure scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of = pp.object_finder(img_path)\n",
    "results = of.find_objects(scale=scale.measured) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks terrible. We need to exclude areas, and pass the mask on to `find_objects`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = pp.polygon_maker(img_path)\n",
    "mask1 = mask.draw(label=\"tray\", mode=\"rectangle\", include=True) # include the tray area\n",
    "mask2 = mask.draw(label=\"scale\", mode=\"rectangle\", show=True, include=False) # exclude the scale inside the tray area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = of.find_objects(mask=[mask1, mask2], scale=scale.measured)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still not great, there is a lot of noise and some bugs are not identified properly. We can try some blurring and implementing a minimum diameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = of.find_objects(mask=[mask1, mask2], scale=scale.measured, min_diam=10, blur1=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blurring tends to \"eat away\" the object borders. We can counteract this by adding a \"correction factor\" that will add some more area to our objects. `corr_factor` is a list that takes three arguments: [shape, value, iterations]. See `help(object_finder)` for details. \n",
    "\n",
    "Since we add more \"flesh to the bone\", we can also increase the minimum diameter of our objects and also introduce `min_area` to get rid of those small particles. Note that the preview that gets put out after every `find_object` run can help you specify those parameters. E.g. if most objects have around 100 pixels and an area >1000 pixels, we want to set the threshold so that the majority stays in, but the smallest objects get excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = of.find_objects(mask=[mask1, mask2], scale=scale.measured, min_diam=20,min_area=1100, blur1=10, corr_factor=[\"ellipse\",10,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this looks good, let's save the results and the processed image for reference, the `idx` column corresponds to the labels inside the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = my_proj.filenames[0]\n",
    "\n",
    "pp.save_csv(df=results, name=img_name, save_dir=\"images_out\")\n",
    "pp.save_img(image=of.image_processed, name=img_name, save_dir=\"images_out\", resize=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object finder - multiple files <a name=\"object3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do this for all the files in our project. Because the tray on which the bugs sit isn't perfectly centered in each picture, we should mark the boundaries with the `polygon_maker`. However, because the scale is the same in each picture, we can use the `detect` method from the `scale_maker` class. `detect` uses the accelerated KAZE (AKAZE: \n",
    "https://www.youtube.com/watch?v=lI50PGr2TEU) algorithm for feature registration and matching. I will expand more on this in a future version of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Project settings - \"My project, 2019-02-15\":\n",
      "\n",
      "\n",
      "Image directory: images\n",
      "Output directory: images_out\n",
      "Mode: dir\n",
      "Filetypes: []\n",
      "Include:['multiple']\n",
      "Exclude: []\n",
      "----------------------------------------------------------------\n",
      "Filenames: \n",
      "['isopods_multiple_1.jpg', 'isopods_multiple_2.jpg', 'isopods_multiple_3.jpg']\n"
     ]
    }
   ],
   "source": [
    "# MAKE FILE LIST\n",
    "\n",
    "my_proj = pp.project_maker(image_dir = \"images\", include=[\"multiple\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mark the outline of the scale by left clicking, remove points by right clicking, finish with enter.\n",
      "Finished, scale outline drawn. Now dd the scale by clicking on two points with a known distance between them:\n",
      "Adding point 1 of 2 to scale\n",
      "Adding point 2 of 2 to scale\n",
      "\n",
      "\n",
      "------------------------------------------------\n",
      "Finished - your scale has 138 pixel per 10 mm.\n",
      "------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# MARK SCALE ONCE, GET PIXEL RATIO\n",
    "\n",
    "img_path = my_proj.filepaths[0] # we only use the first image\n",
    "scale = pp.scale_maker(image=img_path, value=10, unit=\"mm\",  zoom=True, show=True) # measure scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mark the outline of your arena, i.e. what you want to include in the image analysis by left clicking, finish with enter.\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "Scale found with 42 keypoint matches\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "     diameter  area\n",
      "idx                \n",
      "1          96  1429\n",
      "2         109  2141\n",
      "3         117  4116\n",
      "4         101  2650\n",
      "5         102  2217\n",
      "..        ...   ...\n",
      "16         98  1778\n",
      "17         96  2095\n",
      "18        119  2648\n",
      "19        111  1722\n",
      "20         95  1706\n",
      "\n",
      "[20 rows x 2 columns]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Found 26 objects in isopods_multiple_1.jpg:\n",
      "  ==> 20 are valid objects\n",
      "    - 4 are not bigger than minimum diameter\n",
      "    - 6 are not bigger than minimum area\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Mark the outline of your arena, i.e. what you want to include in the image analysis by left clicking, finish with enter.\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "Scale found with 37 keypoint matches\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "     diameter  area\n",
      "idx                \n",
      "1         118  4452\n",
      "2         104  3404\n",
      "3         126  4917\n",
      "4         105  1880\n",
      "5         100  3327\n",
      "..        ...   ...\n",
      "11         98  1559\n",
      "12        102  3273\n",
      "13        165  5238\n",
      "14        104  3020\n",
      "15         85  2186\n",
      "\n",
      "[15 rows x 2 columns]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Found 16 objects in isopods_multiple_2.jpg:\n",
      "  ==> 15 are valid objects\n",
      "    - 1 are not bigger than minimum diameter\n",
      "    - 1 are not bigger than minimum area\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Mark the outline of your arena, i.e. what you want to include in the image analysis by left clicking, finish with enter.\n",
      "\n",
      "\n",
      "--------------------------------------\n",
      "Scale found with 41 keypoint matches\n",
      "--------------------------------------\n",
      "\n",
      "\n",
      "     diameter  area\n",
      "idx                \n",
      "1         102  2899\n",
      "2         109  3970\n",
      "3         102  3574\n",
      "4         118  4370\n",
      "5          74  1571\n",
      "..        ...   ...\n",
      "16        105  2167\n",
      "17        123  4242\n",
      "18        105  3356\n",
      "19         98  2087\n",
      "20        101  2854\n",
      "\n",
      "[20 rows x 2 columns]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Found 35 objects in isopods_multiple_3.jpg:\n",
      "  ==> 20 are valid objects\n",
      "    - 13 are not bigger than minimum diameter\n",
      "    - 15 are not bigger than minimum area\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# MARK TRAY AREA ONLY, SCALE WILL BE AUTOMATICALLY DETECTED. CONTINUE WITH ENTER\n",
    "\n",
    "# loop through both the projects filepaths and filenames using \"zip\":\n",
    "for path, name in zip(my_proj.filepaths, my_proj.filenames):\n",
    "           \n",
    "    # mark the tray for each image. if your picture doesn't change dramatically, you can skip this\n",
    "    arena = pp.polygon_maker(path)\n",
    "    mask1 = arena.draw(label=\"tray\", mode=\"rectangle\", show=True)\n",
    "    \n",
    "    # this is a scale detector! if your scale is identical, the scale-finder will find it!\n",
    "    mask2, scale.current = scale.detect(path, min_matches=10, show=True)    \n",
    "\n",
    "    # we use the optimal settings we found above\n",
    "    of = pp.object_finder(path)\n",
    "    results = of.find_objects(mask=[mask1, mask2], scale=scale.measured, min_diam=20,min_area=1100, blur1=10, corr_factor=[\"ellipse\",10,1])\n",
    "        \n",
    "    # save after every iteration\n",
    "    pp.save_csv(results, name, \"tutorials\\\\images_out\")\n",
    "    pp.save_img(of.image_processed, name, \"tutorials\\\\images_out\", resize=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object finder - variable background <a name=\"object4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the background is not homogenous enough for the standard thresholding algorithm, so we need to use different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Project settings - \"My project, 2019-02-15\":\n",
      "\n",
      "\n",
      "Image directory: images\n",
      "Output directory: images_out\n",
      "Mode: dir\n",
      "Filetypes: []\n",
      "Include:['bug2']\n",
      "Exclude: []\n",
      "----------------------------------------------------------------\n",
      "Filenames: \n",
      "['bug2.jpg']\n"
     ]
    }
   ],
   "source": [
    "my_proj = pp.project_maker(\"images\", include=[\"bug2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning - no scale specified\n",
      "----------------------------------------------------------------\n",
      "Found following object in bug2.jpg:\n",
      "----------------------------------------------------------------\n",
      "     diameter     area\n",
      "idx                   \n",
      "1        1684  1368416\n"
     ]
    }
   ],
   "source": [
    "of = pp.object_finder(image=my_proj.filepaths[0])\n",
    "results = of.find_objects(mode=\"single\", blur1=10) # does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm fails because the image is full of (to us) invisible gradients that make and inhomogenous background. We can make them visible if we change the algorithm, and binarize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning - no scale specified\n",
      "----------------------------------------------------------------\n",
      "Found following object in bug2.jpg:\n",
      "----------------------------------------------------------------\n",
      "     diameter   area\n",
      "idx                 \n",
      "1         382  10097\n"
     ]
    }
   ],
   "source": [
    "results = of.find_objects(mode=\"single\", method=[\"adaptive\", 99,1], show=False) \n",
    "pp.show_img(of.thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning - no scale specified\n",
      "----------------------------------------------------------------\n",
      "Found following object in bug2.jpg:\n",
      "----------------------------------------------------------------\n",
      "     diameter  area\n",
      "idx                \n",
      "1         174  5976\n"
     ]
    }
   ],
   "source": [
    "# and now with proper output\n",
    "results = of.find_objects(mode=\"single\", blur1=10, method=[\"adaptive\", 99,3]) # does work better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.save_csv(results, my_proj.filenames[0], \"images_out\")\n",
    "pp.save_img(of.image_processed, my_proj.filenames[0], \"images_out\", resize=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END - more tutorials to come! If you have questions in the meantime, email me. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
