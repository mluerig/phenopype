{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 3: The three phenopype workflows\n",
    "\n",
    "Analysis of scientific images can be an iterative process that may require users to go back and forth, trying different processing steps and check how to improve results. Later, when the best functions and appropriate settings are found and efficient data collection has priority, image analysis should be efficient and with minimal user input to increase throughput and reproducibility. In phenopype, users can choose from three different workflows that are useful for different stages in the process of scientific image analysis.\n",
    "\n",
    "In all three workflows, users assemble a stack (or sequence) of computer vision functions to analyze an image (Fig 1). The functions are available from phenopypes five core modules: **preprocessing, segmentation, measurement, export and visualization** ([see API reference](api.html#image-analysis-core-modules)). The major difference between the three workflows lies in the degree of code-explicitness, i.e. the need to write code for every step of the analysis, and in the degree of reproducibility, i.e. documentation of code and the results it produces. \n",
    "\n",
    "| Workflow | Use case | Operation principle | Code explicitness | Data reproducibility |\n",
    "|:---|:---------|:------------|:---|:---|\n",
    "| **Prototyping** | analysis prototyping, self education and evaluation | images are loaded as arrays and functions are applied one by one | High | Low |\n",
    "| **Low throughput** | single pictures and very small datasets | images are loaded into phenopype containers | Medium | low |\n",
    "| **High throughput**  | medium and large datasets - default analysis workflow | images are loaded from a phenopype project directory tree, and analyzed with the [pype](api.html#pype-high-throughput-function) method | Low | High |\n",
    "\n",
    "In the **prototyping** and **low throughput** workflow, users write a phenopype function stack in directly in Python code. This is recommended for users who wish to familiarize themselves with the basic principles of computer vision and to explore the phenopype function library. The **high throughput** workflow is for production stage, when image analysis should be efficient and data collection reproducible for other users and scientists. In this tutorial, you will learn the differences between the three workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:600px; text-align: left\" >\n",
    "    \n",
    "![Phenopype workflow example](_assets/workflow_example_case.png)\n",
    "    \n",
    "**Fig. 1:** Workflow demonstration using a stained stickleback (*Gasterosteus aculeatus*) stained with alizarin red. Traits of interest are bone-plate area and shape, and, within the detected plates, pixel intensities that denote bone-density. The computer vision functions used to extract the trait of interest (bone-plate area, shape and pixel density) are the same in all workflows, but workflows differ in the amount of code necessary and in reproducibility. \n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prototyping worflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the prototyping workflow, the output of every function needs to be explicitly passed on to the next step (as seen in [Tutorial 2](tutorial_2_phenopype_images.ipynb)). Every step can be run seperately, or all in one go (if you merged all the code cells). This is useful for phenopype beginners who want to explore what the different functions do, or for troubleshooting, because all intermediate steps can be inspected. \n",
    "\n",
    "First we need to provide the path to an image on the hard drive to `load_image`, which imports the file as a three-channel [1] numpy array (*ndarray*), together with image meta data (file name, exposure, dimensions, etc.) as a pandas *DataFrame*. The array gets passed on to the `threshold` function, which will return a binary array of the same dimensions. This array needs to be passed on to the `find_contours` function, which will return a dictionary with the detected contours. Finally, the dataframe can be exported as a csv file with `save_contours`. By passing on the initially created meta-data, this function will also included filename and image dimensions in the exported csv.  \n",
    "\n",
    "[1] to learn more about the basics of Computer Vision check the [resources section](resources.html) of the phenopype documentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Phenopype prototyping workflow](_assets/workflow_proto.png)\n",
    "<strong>Fig. 2:</strong> Schematic of Phenopype's prototyping workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "filepath = r\"images/stickleback_side.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load image as array, supply image_data (DataFrame containing meta data)\n",
    "image, image_data = pp.load_image(filepath, df = True, meta=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"width:500px; text-align: left\" >\n",
    "    \n",
    "![Create masks](_assets/masks2.gif)\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- creating mask\n"
     ]
    }
   ],
   "source": [
    "## draw mask\n",
    "mask = pp.preprocessing.create_mask(image, tool=\"polygon\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- including pixels from 1 drawn masks \n"
     ]
    }
   ],
   "source": [
    "## thresholding converts multichannel to binary image\n",
    "image_bin = pp.segmentation.threshold(image, method=\"adaptive\", \n",
    "                                      channel=\"red\", blocksize=199, \n",
    "                                      constant=5, df_masks=mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perform morphology operations on binarized image\n",
    "image_morph = pp.segmentation.morphology(image_bin, operation=\"close\", \n",
    "                                         shape=\"ellipse\", kernel_size=3, \n",
    "                                         iterations=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- found 2 contours that match criteria\n"
     ]
    }
   ],
   "source": [
    "## detect contours ony binary image\n",
    "contours = pp.segmentation.find_contours(image_morph, df_image_data=image_data, \n",
    "                                         retrieval=\"ext\", min_area=150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## draw detected contours onto canvas\n",
    "image_drawn = pp.visualization.draw_contours(image, df_contours=contours)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- contours saved under ../_temp/output\\contours.csv (overwritten).\n"
     ]
    }
   ],
   "source": [
    "## export contours to csv\n",
    "pp.export.save_contours(contours, dirpath = r\"../_temp/output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>contour</th>\n",
       "      <th>center</th>\n",
       "      <th>diameter</th>\n",
       "      <th>area</th>\n",
       "      <th>order</th>\n",
       "      <th>idx_child</th>\n",
       "      <th>idx_parent</th>\n",
       "      <th>coords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stickleback_side.jpg</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1563, 747)</td>\n",
       "      <td>118</td>\n",
       "      <td>1923</td>\n",
       "      <td>parent</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[[[1516, 722]], [[1514, 724]], [[1513, 724]], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stickleback_side.jpg</td>\n",
       "      <td>3000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1299, 671)</td>\n",
       "      <td>425</td>\n",
       "      <td>19439</td>\n",
       "      <td>parent</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>[[[1101, 600]], [[1100, 601]], [[1099, 601]], ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  width  height contour       center diameter   area  \\\n",
       "0  stickleback_side.jpg   3000    2000       1  (1563, 747)      118   1923   \n",
       "1  stickleback_side.jpg   3000    2000       2  (1299, 671)      425  19439   \n",
       "\n",
       "    order idx_child idx_parent  \\\n",
       "0  parent        -1         -1   \n",
       "1  parent        -1         -1   \n",
       "\n",
       "                                              coords  \n",
       "0  [[[1516, 722]], [[1514, 724]], [[1513, 724]], ...  \n",
       "1  [[[1101, 600]], [[1100, 601]], [[1099, 601]], ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show convas\n",
    "pp.show_image(image_drawn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While analyzing the image, you can explore output from the different steps to see what is going on. For example, the binary image resulting from the thresholding: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low throughput worflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low throughput workflow is similar to the prototyping workflow, and not intended for work on larger projects. It introduces the phenopype \"container, which is a Python class that incorporates loaded images, dataframes, detected contours, intermediate output, etc. so that they are available for inspection or storage at the end of the analysis. The advantage of using containers is that they donâ€™t litter the global environment and namespace, while still containing all intermediate steps (e.g. binary masks or contour DataFrames). Containers can be used manually to analyze images, but typically they are used automatically within the pype-routine that is part of phenoype's high throughput workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Phenopype low throughput workflow](_assets/workflow_low.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "filepath = r\"images/stickleback_side.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory to save phenopype-container output set at - E:\\git_repos\\phenopype\\_temp\\output\n"
     ]
    }
   ],
   "source": [
    "## load image as a phenopype container which will include all images, dataframes, \n",
    "## detected contours and intermediate output\n",
    "container = pp.load_image(filepath, cont=True, \n",
    "                          dirpath=r\"../_temp/output\", # specifies where the output is stored\n",
    "                         ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- creating mask\n",
      "- including pixels from 1 drawn masks \n",
      "- found 2 contours that match criteria\n",
      "- raw image\n",
      "- contours saved under ../_temp/output\\contours.csv (overwritten).\n"
     ]
    }
   ],
   "source": [
    "## afterwards, same as in the prototyping workflow, functions are applied \n",
    "## directly to the container\n",
    "pp.preprocessing.create_mask(container, tool=\"polygon\") \n",
    "pp.segmentation.threshold(container, method=\"adaptive\", channel=\"red\", \n",
    "                          blocksize=199, constant=5) # 3/4\n",
    "pp.segmentation.morphology(container, operation=\"close\", shape=\"ellipse\", \n",
    "                           kernel_size=3, iterations=3) # 5\n",
    "pp.segmentation.find_contours(container, retrieval=\"ext\", min_area=150) # 6\n",
    "pp.visualization.select_canvas(container, canvas=\"raw\")\n",
    "pp.visualization.draw_contours(container) # 6\n",
    "pp.export.save_contours(container, dirpath = r\"../_temp/output\")\n",
    "pp.show_image(container.canvas) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the intermediate steps from the functions are not present as objects in the namespace, you can access and evaluate it from the container. Again, we will look at the binary image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.show_image(container.image_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `dir` to inspect all the components of the container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', 'canvas', 'df_contours', 'df_image_data', 'df_image_data_copy', 'df_masks', 'dirpath', 'image', 'image_bin', 'image_copy', 'image_data', 'image_gray', 'load', 'reference_manual_mode', 'reset', 'save', 'save_suffix']\n"
     ]
    }
   ],
   "source": [
    "print(dir(container))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High throughput worflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the default workflow to analyse medium and large image datasets in phenopype. Here, instead of writing a sequence of functions in Python, as we did in the prototyping and the high throughput workflow, we open an textfile in human readable `YAML` format. The high throughput is started with the `pype` function, which triggers three actions: \n",
    "\n",
    "1. opening the YAML configuration file in the default OS text editor\n",
    "2. parsing the contained functions and executing them in the sequence\n",
    "3. open a HighGUI window showing the processed image \n",
    "\n",
    "After one iteration of these steps, users can evaluate the results and decide to modify the opened configuration file (e.g. either change function parameters or add new functions), and run `pype` again, or to terminate the `pype`-run and save all results. The processed image, any extracted phenotypic information, as well as the modified config-file is stored inside the image directory. Together with the raw images, which may be either stored separately or within the directory tree, users can thereby provide the full image analysis pipeline to anyone who wishes to reproduce the obtained results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<center>\n",
    "<div style=\"width:600px; text-align: left\" >\n",
    "    \n",
    "![Phenopype high throughput workflow](_assets/workflow_high.png)\n",
    "    \n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:red;font-weight: bold\">IMPORTANT - Read this before continuing</p>\n",
    "\n",
    "When running the `pype` method, hitting `Enter` will finish an interactive step (e.g. creating a mask), and `Ctrl+Enter` will  complete a pype-run and close the window, if exectued after all functions have run (hitting `Enter` will start another `pype`-iteration (without overwriting your work). Closing a window using the builtin close button on the top right will also trigger another `pype` iteration. `Esc` will close windows and end all running Python tasks (useful if you want to interrupt batch analysis with `for` loops, as shown in [Tutorial 4](tutorial_4_managing_projects.ipynb) ). The `pype` method uses HighGUI windows, which can be sometimes unstable - be sure to check [Tutorial 2](tutorial_2_phenopype_images.ipynb#Window-control) \n",
    "\n",
    "At the current stage of development, the pype method is prone to errors resulting from incorrect yaml syntax, e.g. missing spaces or wrong indentation. The pype will still try to run from bottom to top and pass exceptions, but may result in errors that cascade through the function stack. Consult the section [YAML-syntax (below)](#yaml-syntax) to learn how to correctly modify YAML files.\n",
    "\n",
    "A `pype` will attempt to facilitate user experience when working with large data sets, for example, by calling some functions automatically (e.g. from the `visualization` and `export` modules). Also, some functions may not necessarily show their default behavior (e.g. `visualization.save_canvas` will always have `overwrite=True` to save output canvas). Consult the section [pype-behavior](#pype-behavior) to learn about the most important aspects of the `pype` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory to save phenopype-container output set to parent folder of image:\n",
      "E:\\git_repos\\phenopype\\tutorials\\images\n",
      "pype_config_demo.yaml already exists - overwrite?\n",
      "y: yes, file will be overwritten and loaded\n",
      "n: no, existing file will be loaded instead\n",
      "To load an existing file, use \"config\" instead of \"template\".y\n",
      "New pype configuration created (tut3.yaml) from phenopype template:\n",
      "e:\\git_repos\\phenopype\\phenopype\\templates\\tut3.yaml\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2021:03:07 19:37:33 +++--------------\n",
      "\n",
      "\n",
      "=== AUTOLOAD ===\n",
      "- masks_demo.csv\n",
      "PREPROCESSING\n",
      "create_mask\n",
      "- mask with label mask1 already created (edit/overwrite=False)\n",
      "SEGMENTATION\n",
      "threshold\n",
      "- including pixels from 1 drawn masks \n",
      "morphology\n",
      "find_contours\n",
      "- found 2 contours that match criteria\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- invalid selection - defaulting to raw image\n",
      "draw_contours\n",
      "draw_masks\n",
      "drawing mask: mask1\n",
      "EXPORT\n",
      "save_contours\n",
      "- contours saved under ../_temp/output\\contours_demo.csv (overwritten).\n",
      "save_canvas\n",
      "- canvas saved under ../_temp/output\\canvas_demo.jpg (overwritten).\n",
      "=== AUTOSAVE ===\n",
      "save_masks\n",
      "- masks saved under ../_temp/output\\masks_demo.csv (overwritten).\n",
      "\n",
      "\n",
      "------------+++ finished pype iteration +++--------------\n",
      "-------(End with Ctrl+Enter or re-run with Enter)--------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "------------+++ new pype iteration 2021:03:07 19:37:37 +++--------------\n",
      "\n",
      "\n",
      "Nothing loaded.\n",
      "PREPROCESSING\n",
      "create_mask\n",
      "- mask with label mask1 already created (edit/overwrite=False)\n",
      "SEGMENTATION\n",
      "threshold\n",
      "- including pixels from 1 drawn masks \n",
      "morphology\n",
      "find_contours\n",
      "- found 2 contours that match criteria\n",
      "VISUALIZATION\n",
      "select_canvas\n",
      "- invalid selection - defaulting to raw image\n",
      "draw_contours\n",
      "draw_masks\n",
      "drawing mask: mask1\n",
      "EXPORT\n",
      "save_contours\n",
      "- contours saved under ../_temp/output\\contours_demo.csv (overwritten).\n",
      "save_canvas\n",
      "- canvas saved under ../_temp/output\\canvas_demo.jpg (overwritten).\n",
      "=== AUTOSAVE ===\n",
      "save_masks\n",
      "- masks saved under ../_temp/output\\masks_demo.csv (overwritten).\n",
      "\n",
      "\n",
      "------------+++ finished pype iteration +++--------------\n",
      "-------(End with Ctrl+Enter or re-run with Enter)--------\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "TERMINATE\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<phenopype.main.pype at 0x213fa038d88>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "filepath = r\"images/stickleback_side.jpg\"\n",
    "\n",
    "pp.pype(image=filepath, # input - can be also an array or a phenopype directory \n",
    "        dirpath = r\"../_temp/output\", ## directory where output is stored (folder needs to exist)\n",
    "        name=\"demo\", # name of the  pype routine, appended to all results-files \n",
    "        template=\"tut3\" # template for the analysis - you can create your own!\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn how to analyze a lot of images or whole projects with the high-throughput method, move on to the next [Tutorial 4](tutorial_4_managing_projects.ipynb). Also, check the examples (e.g. [Example 2](example_2_landmarks_stickleback.ipynb)), which typically include code for both low and high throughput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YAML syntax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The configuration files needed to run the pype are written in yaml (a recursive acronym for \"YAML Ain't Markup Language\"). In principle, these are just text files that follow a specific syntax that follows rules for [indentation and separation](https://www.tutorialspoint.com/yaml/yaml_indentation_and_separation.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex1.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex1.yaml',\n",
       " 'ex2.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex2.yaml',\n",
       " 'ex3.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex3.yaml',\n",
       " 'ex5_1.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex5_1.yaml',\n",
       " 'ex5_2.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex5_2.yaml',\n",
       " 'ex6.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex6.yaml',\n",
       " 'ex7.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex7.yaml',\n",
       " 'ex8_1.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex8_1.yaml',\n",
       " 'ex8_2.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\ex8_2.yaml',\n",
       " 'tut3.yaml': 'e:\\\\git_repos\\\\phenopype\\\\phenopype\\\\templates\\\\tut3.yaml'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import phenopype as pp\n",
    "\n",
    "pp.pype_config_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHOWING BUILTIN PHENOPYPE TEMPLATE tut3.yaml\n",
      "\n",
      "\n",
      "- preprocessing:\n",
      "  - create_mask:\n",
      "      tool: polygon\n",
      "- segmentation:\n",
      "  - threshold:\n",
      "      method: adaptive\n",
      "      blocksize: 199\n",
      "      constant: 5\n",
      "      channel: red\n",
      "  - morphology:\n",
      "      operation: close\n",
      "      shape: ellipse\n",
      "      kernel_size: 3\n",
      "      iterations: 3\n",
      "  - find_contours:\n",
      "      retrieval: ext\n",
      "      min_diameter: 0\n",
      "      min_area: 150\n",
      "- visualization:\n",
      "  - select_canvas:\n",
      "      canvas: image\n",
      "  - draw_contours:\n",
      "      line_width: 2\n",
      "      label_width: 1\n",
      "      label_size: 1\n",
      "      fill: 0.3\n",
      "  - draw_masks\n",
      "- export:\n",
      "  - save_contours:\n",
      "      overwrite: true\n",
      "  - save_canvas:\n",
      "      resize: 0.5\n",
      "      overwrite: true\n"
     ]
    }
   ],
   "source": [
    "pp.show_config_template(\"tut3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text inside the yaml configuration files is parsed by Python from top to bottom and converted back to Python code in the background, i.e. to phenopype modules and functions. The first level without any indentation, e.g. from the above example `-preprocessing`, `- segmentation`, `- visualization` and `- export`, denote from the core module that a function is part of. The second level, e.g. `- threshold` and `- find_contours` are functions inside the `segmentation` module. The third level without hyphens, e.g. `method: otsu` and `blocksize: 99`, are arguments passed on to the function. Following this notation, the yaml parser in Python would interpret the first item in `segmentation` as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pp.segmentation.threshold(image, method=\"adaptive\", blocksize=199, constant=5, channel=\"red\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running the pype routine, `image` is automatically loaded and passed to all functions. Apart from that you can add or remove functions as you like. Note the hyphen followed by a space in front (`- `) a function: this notation indicates that during parsing the items are interpreted as part of a list. This important, as it allows you to specify the same function as many times as you want.\n",
    "\n",
    "When adding or modifying modules and functions, it is important to keep in mind that the **function stack is executed sequentially**. So, if you want to perform a `morphology` operation on a binary images, it should come *after* and not before the main segmentation function (in this case `threshold`). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the most important rules for YAML syntax:\n",
    "\n",
    "- **indentation rules:**  0 spaces for modules, hyphen+space in front of functions, 4 spaces in front of arguments\n",
    "- **separation rules:** modules and functions with arguments are followed by a colon (`:`) and a new line; functions without specified arguments don't need a colon; arguments are followed by a colon, a space and then the value\n",
    "- modules and functions can be emtpy (e.g. see `measurement:` and `- draw_masks` above), but function arguments *cannot* (e.g. `overwrite:` needs to be `true` or `false`)\n",
    "- as per Python syntax, optional function arguments can, but don't have to be specified and the functions will just run on default values\n",
    "- if you need to add modules (not all presets contain all modules), stick to this order: \n",
    "preprocessing > segmentation > measurement > visualization > export\n",
    "- functions can be added multiple times, but sometimes their output may be overwtritten (e.g. `- threshold` only works once, `- create_mask` multiple times [1])\n",
    " \n",
    "\n",
    "[1] Note that one `create_mask` mask operation already can create multiple masks - see [Tutorial 5](tutorial_5_gui_interactions.ipynb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `pype` behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `pype` function has specific implicit behavior that aims at supporting speed and robustness when working in \"production\" (i.e. when performing the actual analysis of large image datasets compared to prototyping and low throughput workflow). Here I list some important aspects of that behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Window control\n",
    "\n",
    "The `pype` method uses HighGUI windows, which can be sometimes unstable - be sure to check [Tutorial 2](tutorial_2_phenopype_images.ipynb#Window-control). If your text window didn't show up when using the `pype` function, make sure you selected a default text editor to handle YAML files ([see the Installation Instructions](installation.html#choose-a-text-editor)). Here is another summary of the window behavior when working with `pype` in high throughput workflow:\n",
    "\n",
    "- Editing and saving the opened configuration file in the text editor will trigger another `pype` iteration, i.e. close the image window, run the functions in the control file, and display the updated results. \n",
    "- Closing the image window manually (with the X button in the upper right), also runs the functions in the control file, and show the updated results.\n",
    "- `Esc` will close all windows and interrupt the pype routine (`Esc` triggers `sys.exit()`, which will also end a Python session if run from the command line) [1,2] , as well as any loops ([see Tutorial 4](tutorial_4_managing_projects.ipynb#Using-pype-with-project-folders)).\n",
    "- Each step that requires user interaction (e.g. `create_mask` or `landmarks`) needs to be confirmed with `Return` until the next function in the sequence is executed [1,2].\n",
    "- At the end of the analysis, when the final steps (visualization and export functions) have run, you can end the pype routine with another `Return` keystroke [1,2].  \n",
    "\n",
    "\n",
    "[1] Sometimes keystrokes will not be recognized, so they need to be executed multiple times - see [Tutorial 2](tutorial_2_phenopype_images.ipynb).<br>\n",
    "[2] The image window needs to be highlighted to detect keystrokes, not the text editor or the console - see [Tutorial 2](tutorial_2_phenopype_images.ipynb). <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function execution\n",
    "\n",
    "Most important things to keep in mind during a `pype` iteration:\n",
    "\n",
    "- The `pype` function will execute all functions in sequence, but it will not overwrite overwrite data from past iterations on disk unless specified.\n",
    "- To overwrite interactive user input, set the argument `overwrite: true` at the specific function in the configuration file. **Remember to remove it after the next run. [1]**\n",
    "- If a `pype` is initialized on a directory (either from a Phenopype project or a directory specified with the argument `dirpath`), it will attempt to load input data (e.g. masks) that contain the provided `name` argument [2].\n",
    "\n",
    "[1] If you forget to remove an overwrite argument and are prompted to overwrite previous input, simply remove the `overwrite: true` argument, and save to run the `pype` again, it will fall back onto input from the last iteration.<br>\n",
    "[2] For example, `pp.pype(image, name=\"run1\", dirpath=\"path\\to\\directory)` will attempt to load any saved files in `directory` that contains the suffix `\"run1\"` (e.g. `\"masks_run1.csv\"`).<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing the results\n",
    "\n",
    "Aspects of visual feedback during a `pype` run (can be completely suppressed by setting `feedback=False` in the `pype` arguments):\n",
    "\n",
    "- Visual feedback is always generated automatically by an internal function that show results (i.e. output from `landmarks`, `find_contours` or `create_mask`) on top of a \"canvas\". \n",
    "- The canvas can be the image at any step of analytic process (i.e. raw image, binary image, or a colour channel [gray, red, green or blue]) and is selected with `- select_canvas` as part of the `visualization` module. \n",
    "- If `- select_canvas` is not explicitly specified, it is called automatically and defaults to the raw image as canvas. \n",
    "- Output from all functions, needs to be specified manually. For example, after using `- landmarks`, `- draw_landmarks` should be called in the `visualization` module. [1]\n",
    "- Visual parameters of interactive tools (e.g. `point_size` or `line_thickness`) are specified separately in the respective function, *and* in the `visualization` module. \n",
    "\n",
    "[1] Experimental: use the flag `autoshow=True` in the `pype` arguments to automatically show results.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the results\n",
    "\n",
    "Saving results and canvas for quality control:\n",
    "\n",
    "- All results are saved automatically, even if the respective functions in `export` are not specified, with the `name` argument in `pype` as suffix [1,2]. \n",
    "- If a file already exist in the directory, and the respective function is *not* listed under `export:`, then it *will not* be overwritten. If an export function *is* specified under `export:`, it *will overwrite* any existing file [3]\n",
    "- The canvas is an exception: it will always be saved and always be overwritten to show the output from the last iteration. However, users can modify the canvas name with `name` in the arguments to save different output side by side [4].\n",
    "\n",
    "[1] Experimental: use the flag `autosave=False` in the `pype` arguments to deactivate this behavior.<br>\n",
    "[2] For example, `pp.pype(image, name=\"run1\")` will save `\"masks_run1.csv\"` or `\"contours_run1.csv\"`. <br>\n",
    "[3] For example, listing `- save_landmarks` under `export:` will overwrite `landmarks_run1.csv`<br>\n",
    "[4] For example, `name: binary` under `- save_canvas:` save the canvas as `canvas_binary.jpg`<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
