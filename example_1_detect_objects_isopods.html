<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Example 1: Measuring shape, size and colour of isopods &#8212; phenopype 2.0.1 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example 2: Stickleback morphometrics - landmarks" href="example_2_landmarks_stickleback.html" />
    <link rel="prev" title="Tutorial 6: Video analysis" href="tutorial_6_video_analysis.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          phenopype</a>
        <span class="navbar-text navbar-version pull-left"><b>2.0.1</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://github.com/mluerig/phenopype">Phenopype on Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation instructions</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Additional resources</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="tutorial_0.html">How to run tutorials and examples using Jupyter Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_1_python_intro.html">Tutorial 1: A (very) brief python introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_2_phenopype_images.html">Tutorial 2: Interacting with images in phenopype</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_3_phenopype_workflows.html">Tutorial 3: Image analysis workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_4_managing_projects.html">Tutorial 4: Setting up and managing projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_5_references.html">Tutorial 5: Creating and detecting a reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_6_video_analysis.html">Tutorial 6: Video analysis</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Example 1: Measuring shape, size and colour of isopods</a><ul>
<li><a class="reference internal" href="#Low-throughput">Low throughput</a><ul>
<li><a class="reference internal" href="#Loading-the-image">Loading the image</a></li>
<li><a class="reference internal" href="#Drawing-a-mask">Drawing a mask</a></li>
<li><a class="reference internal" href="#Create-size-reference">Create size reference</a></li>
<li><a class="reference internal" href="#Segmentation---1st-attempt">Segmentation - 1st attempt</a></li>
<li><a class="reference internal" href="#Segmentation---2nd-attempt">Segmentation - 2nd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---3rd-attempt">Segmentation - 3rd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---final-product">Segmentation - final product</a></li>
<li><a class="reference internal" href="#Measuring-colour">Measuring colour</a></li>
<li><a class="reference internal" href="#Export">Export</a></li>
</ul>
</li>
<li><a class="reference internal" href="#High-throughput">High throughput</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="tutorial_6_video_analysis.html" title="Previous Chapter: Tutorial 6: Video analysis"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Tutorial 6: V...</span>
    </a>
  </li>
  <li>
    <a href="example_2_landmarks_stickleback.html" title="Next Chapter: Example 2: Stickleback morphometrics - landmarks"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Example 2: St... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/example_1_detect_objects_isopods.ipynb.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Example 1: Measuring shape, size and colour of isopods</a><ul>
<li><a class="reference internal" href="#Low-throughput">Low throughput</a><ul>
<li><a class="reference internal" href="#Loading-the-image">Loading the image</a></li>
<li><a class="reference internal" href="#Drawing-a-mask">Drawing a mask</a></li>
<li><a class="reference internal" href="#Create-size-reference">Create size reference</a></li>
<li><a class="reference internal" href="#Segmentation---1st-attempt">Segmentation - 1st attempt</a></li>
<li><a class="reference internal" href="#Segmentation---2nd-attempt">Segmentation - 2nd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---3rd-attempt">Segmentation - 3rd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---final-product">Segmentation - final product</a></li>
<li><a class="reference internal" href="#Measuring-colour">Measuring colour</a></li>
<li><a class="reference internal" href="#Export">Export</a></li>
</ul>
</li>
<li><a class="reference internal" href="#High-throughput">High throughput</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Example-1:-Measuring-shape,-size-and-colour-of-isopods">
<h1>Example 1: Measuring shape, size and colour of isopods<a class="headerlink" href="#Example-1:-Measuring-shape,-size-and-colour-of-isopods" title="Permalink to this headline">¶</a></h1>
<p>In this example I am demonstrating low and high throughput workflow in phenopype by decomposing the all the required steps for a classic computer vision workflow.</p>
<p>Little nugget of information: this was the original computer vision problem that phenopype was intended to solve (it’s predecessor <a class="reference external" href="https://github.com/mluerig/iso_cv">“iso_cv”</a> was not much more than a script-collection).</p>
<div class="alert alert-block alert-success"><p><strong>Related tutorials, examples and further reading</strong></p>
<ul><li><p>Tutorial 2: Interacting with images in phenopype</p>
</li><li><p>Tutorial 3: The three phenopype workflows</p>
</li><li><p>About the structure of digital images</p>
</li><li><p>About morphological operations</p>
</li></ul></div><div class="row; text-align: left"><div class="col-md-6"><p><img alt="Before" src="_images/ex1_before.jpg" /></p>
<p><strong>Input</strong> - Freshwater isopod, alive, photographed on a white resin-tray from a camera stand.</p>
</div><div class="col-md-6"><p><img alt="After" src="_images/ex1_after.jpg" /></p>
<p><strong>Results</strong> - Isopod shape, size and colour are extracted (and size referenced using the reference card)</p>
</div></div><div class="section" id="Low-throughput">
<h2>Low throughput<a class="headerlink" href="#Low-throughput" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Loading-the-image">
<h3>Loading the image<a class="headerlink" href="#Loading-the-image" title="Permalink to this headline">¶</a></h3>
<p>First we import the image from the a filepath using <code class="docutils literal notranslate"><span class="pre">load_image</span></code>. With the flag <code class="docutils literal notranslate"><span class="pre">df=True</span></code> we can extract some image-meta information that we want to be represented in the results files later (i.e. image name and its dimensions). After loading it, we can have a quick look at it with the <code class="docutils literal notranslate"><span class="pre">show_image</span></code> function - you can close it again with <code class="docutils literal notranslate"><span class="pre">Enter</span></code> or <code class="docutils literal notranslate"><span class="pre">Esc</span></code>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">phenopype</span> <span class="k">as</span> <span class="nn">pp</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">filepath</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;images/isopods.jpg&quot;</span>
<span class="n">image</span><span class="p">,</span> <span class="n">img_data</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">load_image</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span>
                                <span class="n">df</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Drawing-a-mask">
<h3>Drawing a mask<a class="headerlink" href="#Drawing-a-mask" title="Permalink to this headline">¶</a></h3>
<p>The original image has a lot of noise, e.g. the non-white area around the tray, water reflections, the label, the reference card, and the little fecal pellets that lie around on the tray. Classic computer vision algorithms are unspecific to the object, so they will pick up any object that is darker than its environment. Therefore, a useful preprocessing step is to exclude some of that noise by applying a mask. With the <code class="docutils literal notranslate"><span class="pre">create_mask</span></code> function, you can include or exclude certain areas of the
image from the following analysis steps (<code class="docutils literal notranslate"><span class="pre">include=True/False</span></code>).</p>
<p>Here, we want to include all of the wite tray that has isopods in it: Hold the left button down and drag the rectangle shaped mask tool over the area you want to include.</p>
<center><div style="width:500px; text-align: left"><p><img alt="Create masks" src="_images/masks1.gif" /></p>
</div></center><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_masks</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">create_mask</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                        <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- creating mask
</pre></div></div>
</div>
</div>
<div class="section" id="Create-size-reference">
<h3>Create size reference<a class="headerlink" href="#Create-size-reference" title="Permalink to this headline">¶</a></h3>
<p>Within the area we masked lies the reference card. We want to include its information in our results files (the pixel-to-mm-ratio), so we supply the image meta DataFrame with <code class="docutils literal notranslate"><span class="pre">df_image_data=img_data</span></code>. However, we do not want the card itself to be detected, so we mask it with the argument <code class="docutils literal notranslate"><span class="pre">mask=True</span></code> and by supplying or mask DataFrame with <code class="docutils literal notranslate"><span class="pre">df_masks=df_masks</span></code> to have both masks in one place.</p>
<center><div style="width:500px; text-align: left"><p><img alt="Adding a scale" src="_images/ex1_scale.gif" /></p>
</div></center><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">img_data</span><span class="p">,</span> <span class="n">df_masks</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">create_reference</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                                       <span class="n">mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                       <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span>
                                                       <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- measure pixel-to-mm-ratio
Reference set
- add column length
Template selected
Template selected
</pre></div></div>
</div>
<p>Now the <code class="docutils literal notranslate"><span class="pre">df_masks</span></code> DataFrame contains two masks: the one we created above that <em>includes</em> the tray and the one we made to <em>exclude</em> the scale reference card:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_masks</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>coords</th>
      <th>filename</th>
      <th>height</th>
      <th>include</th>
      <th>mask</th>
      <th>width</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>[(239, 166), (1887, 166), (1887, 1349), (239, ...</td>
      <td>isopods.jpg</td>
      <td>1400.0</td>
      <td>1.0</td>
      <td>mask1</td>
      <td>2100.0</td>
    </tr>
    <tr>
      <th>0</th>
      <td>[(446, 1028), (674, 1028), (674, 1223), (446, ...</td>
      <td>isopods.jpg</td>
      <td>1400.0</td>
      <td>0.0</td>
      <td>reference</td>
      <td>2100.0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can now have a quick look at both masks together by calling the visualization function <code class="docutils literal notranslate"><span class="pre">draw_mask</span></code>, followed by <code class="docutils literal notranslate"><span class="pre">show_image</span></code>. For this we should create a new array and <em>not</em> overwrite the original image loaded before - here we call it <code class="docutils literal notranslate"><span class="pre">canvas</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_masks</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                     <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">,</span>
                                     <span class="n">line_width</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
drawing mask: mask1
drawing mask: reference
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---1st-attempt">
<h3>Segmentation - 1st attempt<a class="headerlink" href="#Segmentation---1st-attempt" title="Permalink to this headline">¶</a></h3>
<p>Now that we have removed most of the noise, we can implement an algorithm that segments the imgae into foreground and background (check the <a class="reference external" href="resources.html#computer-vision">resources section</a> of the documentation. Here we use the <code class="docutils literal notranslate"><span class="pre">threshold</span></code> algorithm that to detect the isopods as foreground and the tray as background. By supplying the mask DataFrame we created before with <code class="docutils literal notranslate"><span class="pre">df_masks=masks</span></code>, we can exclude the unwanted regions of the image:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- excluding pixels from 1 drawn masks
- including pixels from 1 drawn masks
</pre></div></div>
</div>
<p>The resulting array <code class="docutils literal notranslate"><span class="pre">image_bin</span></code> is a binary image where white regions are foreground and black background:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image_bin</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>So far so good, but there is still a lot of noise inside the image (isopod fecal pellets) that we need to remove. Right now, all information about foreground and background is in “pixel-space”, i.e. it’s a drawn representation of the informative areas. To convert it to coordinate space, and in the later steps extract information from the raw image, we will use <code class="docutils literal notranslate"><span class="pre">find_contours</span></code> on this binary image. But setting the argument <code class="docutils literal notranslate"><span class="pre">min_area</span></code>, we can set a minimum size for the area that the contours
should have - 100 pixels should be enough to exclude all fecal pellets. Again, we can supply the image meta DataFrame to concatenate existing information. Afterwards we can draw the contours onto <code class="docutils literal notranslate"><span class="pre">canvas</span></code> with <code class="docutils literal notranslate"><span class="pre">draw_contours</span></code> - the detected contours are in green.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_contours</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">image_bin</span><span class="p">,</span> <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">df_contours</span><span class="o">=</span><span class="n">df_contours</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- found 20 contours that match criteria
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---2nd-attempt">
<h3>Segmentation - 2nd attempt<a class="headerlink" href="#Segmentation---2nd-attempt" title="Permalink to this headline">¶</a></h3>
<p>Now we have excluded all noise - but some isopods are not well deteced. Mostly the ones with lighter pigmenation, because the contrast they form agains the light background isn’t strong enough. We can try a different threshold algorithm by setting the <code class="docutils literal notranslate"><span class="pre">method</span></code> argument: <code class="docutils literal notranslate"><span class="pre">&quot;adaptive&quot;</span></code> algorithms work particularly well with variable contrast levels and lighting.</p>
<p>Additionally, instead of using the default gray channel (i.e. the average across all three colour channels), we can try to run the thresholding function on a single colour channel. The contrast and signal-to-noise-ratio can be different betweeen the channels. We can select a different channel using the <code class="docutils literal notranslate"><span class="pre">select_canvas</span></code> function - here I isolate all three colour channels, and supply them to <code class="docutils literal notranslate"><span class="pre">show_image</span></code> to show themm all at once, and to evaluate, which colour-channels is suited best:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">r</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">select_canvas</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                   <span class="n">canvas</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">select_canvas</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                   <span class="n">canvas</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">select_canvas</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                   <span class="n">canvas</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">([</span><span class="n">r</span><span class="p">,</span><span class="n">g</span><span class="p">,</span><span class="n">b</span><span class="p">],</span> <span class="n">max_dim</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span> <span class="c1">## max_dim=reduce window size to 500 pixels on any axis</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- red channel
- green channel
- blue channel
</pre></div></div>
</div>
<p>Looking at this suggests that the green colour channel will yield the best results: here, even the lighter pigmented isopods have a strong contrast against the tray. We can supply either <code class="docutils literal notranslate"><span class="pre">g</span></code> to <code class="docutils literal notranslate"><span class="pre">threshold</span></code>, or directly select this with the <code class="docutils literal notranslate"><span class="pre">channel</span></code> argument:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image_bin</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- excluding pixels from 1 drawn masks
- including pixels from 1 drawn masks
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---3rd-attempt">
<h3>Segmentation - 3rd attempt<a class="headerlink" href="#Segmentation---3rd-attempt" title="Permalink to this headline">¶</a></h3>
<p>Obviously we need to to tune a few things here, way to many things are being detected. Currently the <code class="docutils literal notranslate"><span class="pre">&quot;adaptive&quot;</span></code> algorithm is on default sensitivity (<code class="docutils literal notranslate"><span class="pre">blocksize=99</span></code>), which we can reduce a bit. Also, we can increase the value for the constant to be subtracted after the tresholding with <code class="docutils literal notranslate"><span class="pre">constant</span></code>. We will try <code class="docutils literal notranslate"><span class="pre">blocksize=49</span></code> and <code class="docutils literal notranslate"><span class="pre">constant=5</span></code>. Afterwards, we plot the detected contours back onto the canvas of the original image, not the green channel image</p>
<center><div style="width:800px; text-align: left"><p><img alt="Binarization" src="_images/ex1_binarization.jpg" /></p>
<p><strong>Figure 2</strong> - Demonstration of blocksize (19, 99, 199 - left to right) and constant (1, 5 - top and bottom) parameters. Increasing blocksize leads to better structuring of the pixel level information contained in the image (i.e. larger “blocks” of connected pixels can be detected). This is computationally costly, so it will be slow for large images. Also, there is an optimal value beyond which detection performance will decrease.</p>
</div></center><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                      <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span>
                                      <span class="n">blocksize</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span>
                                      <span class="n">constant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                      <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">,</span>
                                      <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">df_contours</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">image_bin</span><span class="p">,</span>
                                            <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span>
                                            <span class="n">min_area</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                        <span class="n">df_contours</span><span class="o">=</span><span class="n">df_contours</span><span class="p">,</span>
                                        <span class="n">line_width</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- excluding pixels from 1 drawn masks
- including pixels from 1 drawn masks
- found 22 contours that match criteria
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---final-product">
<h3>Segmentation - final product<a class="headerlink" href="#Segmentation---final-product" title="Permalink to this headline">¶</a></h3>
<p>That looks pretty good. The last thing we need to take care of are the appendages (we don’t want to include those) and the gaps that sometimes form between the segments (we want to have that error to be consistent towards no gaps). Some blurring, and a morphological operation will do the trick. Blurring will smooth the contour of the isopods, and a farly large <code class="docutils literal notranslate"><span class="pre">&quot;cross&quot;</span></code> shaped kernel will “cut off” the appendages and other long structures in the binary image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_blurred</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                     <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image_blurred</span><span class="p">,</span>
                                      <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span>
                                      <span class="n">blocksize</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span>
                                      <span class="n">constant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                                      <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">,</span>
                                      <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">image_morph</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">morphology</span><span class="p">(</span><span class="n">image_bin</span><span class="p">,</span>
                                         <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;open&quot;</span><span class="p">,</span>
                                         <span class="n">shape</span><span class="o">=</span><span class="s2">&quot;cross&quot;</span><span class="p">,</span>
                                         <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span>
                                         <span class="n">iterations</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">contours</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">image_morph</span><span class="p">,</span>
                                         <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span>
                                         <span class="n">min_area</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_masks</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                     <span class="n">df_masks</span><span class="o">=</span><span class="n">df_masks</span><span class="p">,</span>
                                     <span class="n">line_width</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span>
                                        <span class="n">df_contours</span><span class="o">=</span><span class="n">contours</span><span class="p">,</span>
                                        <span class="n">line_width</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- excluding pixels from 1 drawn masks
- including pixels from 1 drawn masks
- found 20 contours that match criteria
drawing mask: mask1
drawing mask: reference
</pre></div></div>
</div>
</div>
<div class="section" id="Measuring-colour">
<h3>Measuring colour<a class="headerlink" href="#Measuring-colour" title="Permalink to this headline">¶</a></h3>
<p>Ok, this looks good - we now have a DataFrame with the contour-data of all 20 isopods, including their length (<code class="docutils literal notranslate"><span class="pre">diameter</span></code> of the enclosing circle), and the shape (<code class="docutils literal notranslate"><span class="pre">coords</span></code>). Using this information, we can finally extract the colour information from inside the contours. To do so we can supply the original image array along with the contour DataFrame to the <code class="docutils literal notranslate"><span class="pre">colour_intensity</span></code> function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pigmentation</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">measurement</span><span class="o">.</span><span class="n">colour_intensity</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                               <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span>
                                               <span class="n">df_contours</span><span class="o">=</span><span class="n">contours</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Export">
<h3>Export<a class="headerlink" href="#Export" title="Permalink to this headline">¶</a></h3>
<p>Done - we can now save the contours and the colour information to csv, as well as the canvas for quality control:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save_contours</span><span class="p">(</span><span class="n">contours</span><span class="p">,</span>
                        <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;_temp/output/ex1&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save_colours</span><span class="p">(</span><span class="n">pigmentation</span><span class="p">,</span>
                       <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;_temp/output/ex1&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save_canvas</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span>
                      <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;_temp/output/ex1&quot;</span><span class="p">)</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- contours saved under _temp/output/ex1\contours.csv (overwritten).
- colours saved under _temp/output/ex1\colours.csv (overwritten).
- canvas saved under _temp/output/ex1\canvas.jpg (overwritten).
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="High-throughput">
<h2>High throughput<a class="headerlink" href="#High-throughput" title="Permalink to this headline">¶</a></h2>
<p>Now we will use the <code class="docutils literal notranslate"><span class="pre">pype</span></code> method to detect the isopods. For more information on how to analyze multiple images and whole datasets with this approach, check <a class="reference external" href="tutorial_3_phenopype_workflow.ipynb">Tutorial 3</a>.</p>
<center><div style="width:600px; text-align: left"><p><img alt="Phenopype high throughput workflow" src="_images/workflow_high.png" /></p>
</div></center><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">phenopype</span> <span class="k">as</span> <span class="nn">pp</span>
</pre></div>
</div>
</div>
<p>For convenience, the appropriate settings for this example are contained in a template named <code class="docutils literal notranslate"><span class="pre">ex1</span></code>, which we can supply directly to the <code class="docutils literal notranslate"><span class="pre">pype</span></code>. Note that we need to rename this run, otherwise the <code class="docutils literal notranslate"><span class="pre">pype</span></code> will reload our old settings (you can also just delete them in the folder).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">pype_config_templates</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
{&#39;demo.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\demo.yaml&#39;,
 &#39;ex1.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex1.yaml&#39;,
 &#39;ex2.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex2.yaml&#39;,
 &#39;ex3.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex3.yaml&#39;,
 &#39;ex5_1.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex5_1.yaml&#39;,
 &#39;ex5_2.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex5_2.yaml&#39;,
 &#39;ex6.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex6.yaml&#39;,
 &#39;ex7.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex7.yaml&#39;,
 &#39;ex8_1.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex8_1.yaml&#39;,
 &#39;ex8_2.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\ex8_2.yaml&#39;,
 &#39;landmarks1.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\landmarks1.yaml&#39;,
 &#39;landmarks2.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\landmarks2.yaml&#39;,
 &#39;tut3.yaml&#39;: &#39;d:\\workspace\\git\\phenopype\\phenopype\\templates\\tut3.yaml&#39;}
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">show_config_template</span><span class="p">(</span><span class="s2">&quot;ex1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
SHOWING BUILTIN PHENOPYPE TEMPLATE ex1.yaml


- preprocessing:
  - create_mask
  - create_reference:
      mask: true
- segmentation:
  - blur:
      kernel_size: 15
  - threshold:
      method: adaptive
      blocksize: 49
      constant: 5
      channel: green
  - morphology:
      operation: open
      shape: cross
      kernel_size: 9
      iterations: 2
  - find_contours:
      retrieval: ccomp
      min_diameter: 0
      min_area: 250
- visualization:
  - select_canvas:
      canvas: image
  - draw_contours:
      line_width: 2
      label_width: 1
      label_size: 1
      fill: 0.3
- export:
  - save_contours:
      overwrite: true
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">pype</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;iso2&quot;</span><span class="p">,</span>
        <span class="n">template</span><span class="o">=</span><span class="s2">&quot;ex1&quot;</span><span class="p">,</span>
        <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;_temp/output/ex1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Directory to save phenopype-container output set to parent folder of image:
D:\workspace\git\phenopype\tutorials\images
pype_config_iso2.yaml already exists - overwrite?
y: yes, file will be overwritten and loaded
n: no, existing file will be loaded instead
To load an existing file, use &#34;config&#34; instead of &#34;template&#34;.y
New pype configuration created (ex1.yaml) from phenopype template:
d:\workspace\git\phenopype\phenopype\templates\ex1.yaml


------------+++ new pype iteration 2021:05:10 15:28:18 +++--------------


=== AUTOLOAD ===
- masks_iso2.csv
PREPROCESSING
create_mask
- mask with label mask1 already created (edit/overwrite=False)
create_reference
- measure pixel-to-mm-ratio
Reference set
- add column length
Template selected
- reference template mask already created (overwrite=False)
SEGMENTATION
blur
threshold
- excluding pixels from 1 drawn masks
- including pixels from 1 drawn masks
morphology
find_contours
- found 20 contours that match criteria
VISUALIZATION
select_canvas
- invalid selection - defaulting to raw image
draw_contours
EXPORT
save_contours
- contours saved under _temp/output/ex1\contours_iso2.csv (overwritten).
=== AUTOSAVE ===
save_canvas
- canvas saved under _temp/output/ex1\canvas_iso2.jpg (overwritten).
save_masks
- masks saved under _temp/output/ex1\masks_iso2.csv (overwritten).


------------+++ finished pype iteration +++--------------
-------(End with Ctrl+Enter or re-run with Enter)--------




TERMINATE
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;phenopype.main.pype at 0x2891ae2ebc8&gt;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2021, Moritz Lürig.<br/>
      Last updated on May 10, 2021, 5:17:54 PM.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>