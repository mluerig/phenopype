<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Example 1: Measuring shape, size and colour of isopods &#8212; phenopype 1.0.3 documentation</title>
    <link rel="stylesheet" href="_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Example 2: Stickleback morphometrics - landmarks" href="example_2_landmarks_stickleback.html" />
    <link rel="prev" title="Tutorial 6: Video analysis" href="tutorial_6_video_analysis.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="index.html">
          phenopype</a>
        <span class="navbar-text navbar-version pull-left"><b>1.0.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://github.com/mluerig/phenopype">Phenopype on Github</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="api.html">API reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="resources.html">Additional resources</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="tutorial_0.html">How to run the tutorials and examples using Jupyter Notebook</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_1_python_intro.html">Tutorial 1: A (very) brief python introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_2_phenopype_workflow.html">Tutorial 2: Working with phenopype (prototyping, low throughput, high throughput)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_3_managing_projects_1.html">Tutorial 3: Setting up and managing phenopype projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_4_managing_projects_2.html">Tutorial 4: Project wide variables (e.g. size and colour reference)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_5_gui_interactions.html">Tutorial 5: GUI interactions (masks, lines and drawing tools)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_6_video_analysis.html">Tutorial 6: Video analysis</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Example 1: Measuring shape, size and colour of isopods</a><ul>
<li><a class="reference internal" href="#Prototyping">Prototyping</a><ul>
<li><a class="reference internal" href="#Loading-the-image">Loading the image</a></li>
<li><a class="reference internal" href="#Drawing-a-mask">Drawing a mask</a></li>
<li><a class="reference internal" href="#Create-size-reference">Create size reference</a></li>
<li><a class="reference internal" href="#Segmentation---1st-attempt">Segmentation - 1st attempt</a></li>
<li><a class="reference internal" href="#Segmentation---2nd-attempt">Segmentation - 2nd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---3rd-attempt">Segmentation - 3rd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---final-product">Segmentation - final product</a></li>
<li><a class="reference internal" href="#Measuring-colour">Measuring colour</a></li>
<li><a class="reference internal" href="#Export">Export</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Low-throughput">Low throughput</a></li>
<li><a class="reference internal" href="#High-throughput">High throughput</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="tutorial_6_video_analysis.html" title="Previous Chapter: Tutorial 6: Video analysis"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Tutorial 6: V...</span>
    </a>
  </li>
  <li>
    <a href="example_2_landmarks_stickleback.html" title="Next Chapter: Example 2: Stickleback morphometrics - landmarks"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Example 2: St... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="_sources/example_1_detect_objects_isopods.ipynb.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Example 1: Measuring shape, size and colour of isopods</a><ul>
<li><a class="reference internal" href="#Prototyping">Prototyping</a><ul>
<li><a class="reference internal" href="#Loading-the-image">Loading the image</a></li>
<li><a class="reference internal" href="#Drawing-a-mask">Drawing a mask</a></li>
<li><a class="reference internal" href="#Create-size-reference">Create size reference</a></li>
<li><a class="reference internal" href="#Segmentation---1st-attempt">Segmentation - 1st attempt</a></li>
<li><a class="reference internal" href="#Segmentation---2nd-attempt">Segmentation - 2nd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---3rd-attempt">Segmentation - 3rd attempt</a></li>
<li><a class="reference internal" href="#Segmentation---final-product">Segmentation - final product</a></li>
<li><a class="reference internal" href="#Measuring-colour">Measuring colour</a></li>
<li><a class="reference internal" href="#Export">Export</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Low-throughput">Low throughput</a></li>
<li><a class="reference internal" href="#High-throughput">High throughput</a></li>
</ul>
</li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    min-width: 5.5ex;
    padding-top: 0.3rem;
    padding-right: 0.3rem;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 0.3rem;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<div class="section" id="Example-1:-Measuring-shape,-size-and-colour-of-isopods">
<h1>Example 1: Measuring shape, size and colour of isopods<a class="headerlink" href="#Example-1:-Measuring-shape,-size-and-colour-of-isopods" title="Permalink to this headline">¶</a></h1>
<p>In this example I am demonstrating all three phenopype workflows (<a class="reference external" href="#Prototyping">prototyping</a>, <a class="reference external" href="#Low-throughput">low thoughput</a> and <a class="reference external" href="#High-throughput">high throughput</a>). For a project, you would probably only use either the high or low throughput approach, but the protoypting approach for this example decomposes the all the required steps for a classic computer vision workflow.</p>
<p>If you haven’t done so yet, have a look at <a class="reference internal" href="tutorial_2_phenopype_workflow.html"><span class="doc">Tutorial 2</span></a> where the different workflows and their features are explained.</p>
<p>Little nugget of information: this was the original computer vision problem that phenopype was intended to solve (it’s predecessor <a class="reference external" href="https://github.com/mluerig/iso_cv">“iso_cv”</a> was not much more than a script-collection).</p>
<div class="row; text-align: left"><div class="col-md-6"><p><img alt="Before" src="_images/ex1_before.jpg" /></p>
<p><strong>Input</strong> - Freshwater isopod, alive, photographed on a white resin-tray from a camera stand.</p>
</div><div class="col-md-6"><p><img alt="After" src="_images/ex1_after.jpg" /></p>
<p><strong>Results</strong> - Isopod shape, size and colour are extracted (and size referenced using the reference card)</p>
</div></div><div class="section" id="Prototyping">
<h2>Prototyping<a class="headerlink" href="#Prototyping" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Loading-the-image">
<h3>Loading the image<a class="headerlink" href="#Loading-the-image" title="Permalink to this headline">¶</a></h3>
<p>First we import the image from the a filepath using <code class="docutils literal notranslate"><span class="pre">load_image</span></code>. With the flag <code class="docutils literal notranslate"><span class="pre">df=True</span></code> we can extract some image-meta information that we want to be represented in the results files later (i.e. image name and its dimensions). After loading it, we can have a quick look at it with the <code class="docutils literal notranslate"><span class="pre">show_image</span></code> function - you can close it again with Enter or Esc.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">phenopype</span> <span class="k">as</span> <span class="nn">pp</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">filepath</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;images/isopods.jpg&quot;</span>
<span class="n">image</span><span class="p">,</span> <span class="n">img_data</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">load_image</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">img_data</span> <span class="c1">## size ratio refers whether this image has been resized using the resize argument of `load_image`</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>width</th>
      <th>height</th>
      <th>size_ratio_original</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>isopods.jpg</td>
      <td>2100</td>
      <td>1400</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
</div>
<div class="section" id="Drawing-a-mask">
<h3>Drawing a mask<a class="headerlink" href="#Drawing-a-mask" title="Permalink to this headline">¶</a></h3>
<p>The original image has a lot of noise, e.g. the non-white area around the tray, water reflections, the label, the reference card, and the little fecal pellets that lie around on the tray. Classic computer vision algorithms are unspecific to the object, so they will pick up any object that is darker than its environment. Therefore, a useful preprocessing step is to exclude some of that noise by applying a mask. With the <code class="docutils literal notranslate"><span class="pre">create_mask</span></code> function, you can include or exclude certain areas of the
image from the following analysis steps (<code class="docutils literal notranslate"><span class="pre">include=True/False</span></code>).</p>
<p>Here, we want to include all of the wite tray that has isopods in it: Hold the left button down and drag the rectangle shaped mask tool over the area you want to include (for more details on the mask and other interaction-tools, see <a class="reference internal" href="tutorial_5_gui_interactions.html"><span class="doc">Tutorial 5</span></a>).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">masks</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">create_mask</span><span class="p">(</span><span class="n">image</span><span class="p">,</span><span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- create mask
</pre></div></div>
</div>
</div>
<div class="section" id="Create-size-reference">
<h3>Create size reference<a class="headerlink" href="#Create-size-reference" title="Permalink to this headline">¶</a></h3>
<p>Within the area we masked lies the reference card. We want to include its information in our results files (the pixel-to-mm-ratio), so we supply the image meta DataFrame with <code class="docutils literal notranslate"><span class="pre">df_image_data=img_data</span></code>. However, we do not want the card itself to be detected, so we mask it with the argument <code class="docutils literal notranslate"><span class="pre">mask=True</span></code> and by supplying or mask DataFrame with <code class="docutils literal notranslate"><span class="pre">df_masks=masks</span></code> to have both masks in one place.</p>
<center><div style="width:500px; text-align: left"><p><img alt="Adding a scale" src="_images/ex1_scale.gif" /></p>
</div></center><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">img_data</span><span class="p">,</span> <span class="n">masks</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">create_scale</span><span class="p">(</span><span class="n">image</span><span class="p">,</span>
                                                <span class="n">mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                                <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span>
                                                <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- measure pixel-to-mm-ratio
Scale set
- add column length
Template selected
</pre></div></div>
</div>
<p>Now the <code class="docutils literal notranslate"><span class="pre">masks</span></code> DataFrame contains two masks: the one we created above that <em>includes</em> the tray and the one we made to <em>exclude</em> the scale reference card:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">masks</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>width</th>
      <th>height</th>
      <th>size_ratio_original</th>
      <th>mask</th>
      <th>include</th>
      <th>coords</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>isopods.jpg</td>
      <td>2100</td>
      <td>1400</td>
      <td>1</td>
      <td>mask1</td>
      <td>True</td>
      <td>[(515, 1067), (515, 1067), (515, 1067), (515, ...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>isopods.jpg</td>
      <td>2100</td>
      <td>1400</td>
      <td>1</td>
      <td>mask1</td>
      <td>True</td>
      <td>[(247, 187), (1894, 187), (1894, 1339), (247, ...</td>
    </tr>
    <tr>
      <th>0</th>
      <td>isopods.jpg</td>
      <td>2100</td>
      <td>1400</td>
      <td>1</td>
      <td>scale</td>
      <td>False</td>
      <td>[(441, 1017), (682, 1017), (682, 1229), (441, ...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>We can now have a quick look at both masks together by calling the visualization function <code class="docutils literal notranslate"><span class="pre">draw_mask</span></code>, followed by <code class="docutils literal notranslate"><span class="pre">show_image</span></code>. For this we should create a new array and <em>not</em> overwrite the original image loaded before - here we call it <code class="docutils literal notranslate"><span class="pre">canvas</span></code>:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_masks</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span> <span class="n">line_width</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 - show mask: mask1.
 - show mask: mask1.
 - show mask: scale.
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---1st-attempt">
<h3>Segmentation - 1st attempt<a class="headerlink" href="#Segmentation---1st-attempt" title="Permalink to this headline">¶</a></h3>
<p>Now that we have removed most of the noise, we can implement an algorithm that segments the imgae into foreground and background (check the <a class="reference external" href="resources.html#computer-vision">resources section</a> of the documentation. Here we use the <code class="docutils literal notranslate"><span class="pre">threshold</span></code> algorithm that to detect the isopods as foreground and the tray as background. By supplying the mask DataFrame we created before with <code class="docutils literal notranslate"><span class="pre">df_masks=masks</span></code>, we can exclude the unwanted regions of the image:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- applying mask: mask1
- applying mask: mask1
- applying mask: scale
</pre></div></div>
</div>
<p>The resulting array <code class="docutils literal notranslate"><span class="pre">image_bin</span></code> is a binary image where white regions are foreground and black background:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image_bin</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>So far so good, but there is still a lot of noise inside the image (isopod fecal pellets) that we need to remove. Right now, all information about foreground and background is in “pixel-space”, i.e. it’s a drawn representation of the informative areas. To convert it to coordinate space, and in the later steps extract information from the raw image, we will use <code class="docutils literal notranslate"><span class="pre">find_contours</span></code> on this binary image. But setting the argument <code class="docutils literal notranslate"><span class="pre">min_area</span></code>, we can set a minimum size for the area that the contours
should have - 100 pixels should be enough to exclude all fecal pellets. Again, we can supply the image meta DataFrame to concatenate existing information. Afterwards we can draw the contours onto <code class="docutils literal notranslate"><span class="pre">canvas</span></code> with <code class="docutils literal notranslate"><span class="pre">draw_contours</span></code> - the detected contours are in green.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">df_contours</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">image_bin</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">df_contours</span><span class="o">=</span><span class="n">df_contours</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Segmentation---2nd-attempt">
<h3>Segmentation - 2nd attempt<a class="headerlink" href="#Segmentation---2nd-attempt" title="Permalink to this headline">¶</a></h3>
<p>Now we have excluded all noise - but some isopods are not well deteced. Mostly the ones with lighter pigmenation, because the contrast they form agains the light background isn’t strong enough. We can try a different threshold algorithm by setting the <code class="docutils literal notranslate"><span class="pre">method</span></code> argument: <code class="docutils literal notranslate"><span class="pre">&quot;adaptive&quot;</span></code> algorithms work particularly well with variable contrast levels and lighting.</p>
<p>Additionally, instead of using the default gray channel (i.e. the average across all three colour channels), we can try to run the thresholding function on a single colour channel. The contrast and signal-to-noise-ratio can be different betweeen the channels. We can select a different channel using the <code class="docutils literal notranslate"><span class="pre">select_canvas</span></code> function - here I isolate all three colour channels, and supply them to <code class="docutils literal notranslate"><span class="pre">show_image</span></code> to show themm all at once, and to evaluate, which colour-channels is suited best:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">r</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">select_canvas</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">canvas</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">g</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">select_canvas</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">canvas</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">select_canvas</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">canvas</span><span class="o">=</span><span class="s2">&quot;b&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">([</span><span class="n">r</span><span class="p">,</span><span class="n">g</span><span class="p">,</span><span class="n">b</span><span class="p">],</span> <span class="n">max_dim</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span> <span class="c1">## max_dim=reduce window size to 500 pixels on any axis</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- red channel
- green channel
- blue channel
</pre></div></div>
</div>
<p>Looking at this suggests that the green colour channel will yield the best results: here, even the lighter pigmented isopods have a strong contrast against the tray. We can supply either <code class="docutils literal notranslate"><span class="pre">g</span></code> to <code class="docutils literal notranslate"><span class="pre">threshold</span></code>, or directly select this with the <code class="docutils literal notranslate"><span class="pre">channel</span></code> argument:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image_bin</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- applying mask: mask1
- applying mask: mask1
- applying mask: scale
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---3rd-attempt">
<h3>Segmentation - 3rd attempt<a class="headerlink" href="#Segmentation---3rd-attempt" title="Permalink to this headline">¶</a></h3>
<p>Obviously we need to to tune a few things here, waay to many things are being detected. Currently the <code class="docutils literal notranslate"><span class="pre">&quot;adaptive&quot;</span></code> algorithm is on default sensitivity (<code class="docutils literal notranslate"><span class="pre">blocksize=99</span></code>), which we can reduce a bit. Also, we can increase the value for the constant to be subtracted after the tresholding with <code class="docutils literal notranslate"><span class="pre">constant</span></code>. We will try <code class="docutils literal notranslate"><span class="pre">blocksize=49</span></code> and <code class="docutils literal notranslate"><span class="pre">constant=5</span></code>. Afterwards, we plot the detected contours back onto the canvas of the original image, not the green channel image</p>
<center><div style="width:800px; text-align: left"><p><img alt="Binarization" src="_images/ex1_binarization.jpg" /></p>
<p><strong>Figure 2</strong> - Demonstration of blocksize (19, 99, 199 - left to right) and constant (1, 5 - top and bottom) parameters. Increasing blocksize leads to better structuring of the pixel level information contained in the image (i.e. larger “blocks” of connected pixels can be detected). This is computationally costly, so it will be slow for large images. Also, there is an optimal value beyond which detection performance will decrease.</p>
</div></center><div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span>
                                      <span class="n">constant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">df_contours</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">image_bin</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">df_contours</span><span class="o">=</span><span class="n">df_contours</span><span class="p">,</span> <span class="n">line_width</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- applying mask: mask1
- applying mask: mask1
- applying mask: scale
</pre></div></div>
</div>
</div>
<div class="section" id="Segmentation---final-product">
<h3>Segmentation - final product<a class="headerlink" href="#Segmentation---final-product" title="Permalink to this headline">¶</a></h3>
<p>That looks pretty good. The last thing we need to take care of are the appendages (we don’t want to include those) and the gaps that sometimes form between the segments (we want to have that error to be consistent towards no gaps). Some blurring, and a morphological operation will do the trick (see <a class="reference external" href="https://docs.opencv.org/3.4.9/d9/d61/tutorial_py_morphological_ops.html">the OpenCV docs</a> and the <a class="reference external" href="resources.html#computer-vision">resources section</a> of the documentation for more info).
Blurring will smooth the contour of the isopods, and a farly large <code class="docutils literal notranslate"><span class="pre">&quot;cross&quot;</span></code> shaped kernel will “cut off” the appendages and other long structures in the binary image.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">image_blurred</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">image_bin</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">image_blurred</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span>
                                      <span class="n">constant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span>  <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">image_morph</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">morphology</span><span class="p">(</span><span class="n">image_bin</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;open&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="s2">&quot;cross&quot;</span><span class="p">,</span>
                                         <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="n">contours</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">image_morph</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_masks</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">df_masks</span><span class="o">=</span><span class="n">masks</span><span class="p">,</span> <span class="n">line_width</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">canvas</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">df_contours</span><span class="o">=</span><span class="n">contours</span><span class="p">,</span> <span class="n">line_width</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- applying mask: mask1
- applying mask: mask1
- applying mask: scale
 - show mask: mask1.
 - show mask: mask1.
 - show mask: scale.
</pre></div></div>
</div>
</div>
<div class="section" id="Measuring-colour">
<h3>Measuring colour<a class="headerlink" href="#Measuring-colour" title="Permalink to this headline">¶</a></h3>
<p>Ok, this looks good - we now have a DataFrame with the contour-data of all 20 isopods, including their length (<code class="docutils literal notranslate"><span class="pre">diameter</span></code> of the enclosing circle), and the shape (<code class="docutils literal notranslate"><span class="pre">coords</span></code>). Using this information, we can finally extract the colour information from inside the contours. To do so we can supply the original image array along with the contour DataFrame to the <code class="docutils literal notranslate"><span class="pre">colour_intensity</span></code> function:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pigmentation</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">measurement</span><span class="o">.</span><span class="n">colour_intensity</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">df_image_data</span><span class="o">=</span><span class="n">img_data</span><span class="p">,</span> <span class="n">df_contours</span><span class="o">=</span><span class="n">contours</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Export">
<h3>Export<a class="headerlink" href="#Export" title="Permalink to this headline">¶</a></h3>
<p>Done - we can now save the contours and the colour information to csv, as well as the canvas for quality control:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save_contours</span><span class="p">(</span><span class="n">contours</span><span class="p">,</span> <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;../_temp/output&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save_colours</span><span class="p">(</span><span class="n">pigmentation</span><span class="p">,</span> <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;../_temp/output&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save_canvas</span><span class="p">(</span><span class="n">canvas</span><span class="p">,</span> <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;../_temp/output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- contours saved under ../_temp/output\contours.csv (overwritten).
- colours saved under ../_temp/output\colours.csv (overwritten).
- canvas saved under ../_temp/output\canvas.jpg (overwritten).
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Low-throughput">
<h2>Low throughput<a class="headerlink" href="#Low-throughput" title="Permalink to this headline">¶</a></h2>
<p>In the low throughput approach we will apply the very same functions as in the prototyping approach. However, we use the knowledge acquired before (i.e. good settings for the segmentation functions). Notice that less objects are created because the intermediate output is stored in the container. This makes for a cleaner workspace, but may conceal which steps have already been performed.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">phenopype</span> <span class="k">as</span> <span class="nn">pp</span>
</pre></div>
</div>
</div>
<p>Load image.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">filepath</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;images/isopods.jpg&quot;</span>

<span class="n">ct</span> <span class="o">=</span> <span class="n">pp</span><span class="o">.</span><span class="n">load_image</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">cont</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">## load image as container</span>
</pre></div>
</div>
</div>
<p>Mask the edges of the tray, measure the reference card, and mask it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">create_mask</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">create_scale</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">template</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">ct</span><span class="o">.</span><span class="n">df_masks</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- create mask
- measure pixel-to-mm-ratio
Scale set
- add column length
Template selected
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>filename</th>
      <th>width</th>
      <th>height</th>
      <th>size_ratio_original</th>
      <th>mask</th>
      <th>include</th>
      <th>coords</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>isopods.jpg</td>
      <td>2100</td>
      <td>1400</td>
      <td>1</td>
      <td>mask1</td>
      <td>True</td>
      <td>[(258, 182), (1898, 182), (1898, 1357), (258, ...</td>
    </tr>
    <tr>
      <th>0</th>
      <td>isopods.jpg</td>
      <td>2100</td>
      <td>1400</td>
      <td>1</td>
      <td>scale</td>
      <td>False</td>
      <td>[(443, 1021), (684, 1021), (684, 1233), (443, ...</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>Write mask to canvas and show it.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_masks</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span>

<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
 - show mask: mask1.
 - show mask: scale.
</pre></div></div>
</div>
<p>First blur the image, then use <code class="docutils literal notranslate"><span class="pre">threshold</span></code> to segment it. Note that any masks in the container will be automatically applied. Afterwards, morphology operations are applied to the binary image.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">blur</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">15</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">threshold</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s2">&quot;adaptive&quot;</span><span class="p">,</span> <span class="n">blocksize</span><span class="o">=</span><span class="mi">49</span><span class="p">,</span>
                                      <span class="n">constant</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">channel</span><span class="o">=</span><span class="s2">&quot;green&quot;</span><span class="p">)</span>
<span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">morphology</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">operation</span><span class="o">=</span><span class="s2">&quot;open&quot;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="s2">&quot;cross&quot;</span><span class="p">,</span>
                                         <span class="n">kernel_size</span> <span class="o">=</span> <span class="mi">9</span><span class="p">,</span> <span class="n">iterations</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
- applying mask: mask1
- applying mask: scale
</pre></div></div>
</div>
<p>Find the contours…</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">segmentation</span><span class="o">.</span><span class="n">find_contours</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">min_area</span><span class="o">=</span><span class="mi">250</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>… draw them onto the canvas, and show them:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">draw_contours</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span>

<span class="n">pp</span><span class="o">.</span><span class="n">show_image</span><span class="p">(</span><span class="n">ct</span><span class="o">.</span><span class="n">canvas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Finally, use container’s builtin autosave function <code class="docutils literal notranslate"><span class="pre">save</span></code> and export all contours and masks and the canvas. If you don’t set the <code class="docutils literal notranslate"><span class="pre">dirpath</span></code> argument it will save all files to the directory that the original image is located in.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ct</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;../_temp/output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
AUTOSAVE
save_canvas
- canvas saved under ../_temp/output\canvas.jpg (overwritten).
save_contours
- contours not saved - file already exists (overwrite=False).
save_masks
- masks not saved - file already exists (overwrite=False).
</pre></div></div>
</div>
<p><strong>Note:</strong> if you need to redo an analysis using the container, you should reset it with it’s builtin <code class="docutils literal notranslate"><span class="pre">reset</span></code> method. Otherwise you may end up trying to binarize an image that is already binary, which will give unexpected, wront results.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">ct</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="High-throughput">
<h2>High throughput<a class="headerlink" href="#High-throughput" title="Permalink to this headline">¶</a></h2>
<p>Now we will use the <code class="docutils literal notranslate"><span class="pre">pype</span></code> method to detect the isopods. For more information on how to analyze multiple images and whole datasets with this approach, check <a class="reference internal" href="tutorial_2_phenopype_workflow.html"><span class="doc">Tutorial 2</span></a>, <a class="reference internal" href="tutorial_3_managing_projects_1.html"><span class="doc">Tutorial 3</span></a> and <a class="reference internal" href="example_2_landmarks_stickleback.html"><span class="doc">Example 2</span></a>.</p>
<center><div style="text-align: left"><p><img alt="Phenopype high throughput workflow" src="_images/workflow_high.png" /></p>
</div></center><p>The idea of the pype method is to control the image analysis workflow from within a configuration file. While you modify that file, saving the changes will immediately update the reiterate the contained functions and show the results. After you finish, all settings needed to reproduce the results will be contained inside the configuration file.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">pype</span></code> can be initialized with the path to the image, and a name that will be appended to all results-files and the the configuration file that is created. Providing different names allows you to run and save multiple analyses side by side. Here we will use the <code class="docutils literal notranslate"><span class="pre">object_detection_morph</span></code> template, which contains preset instructions for object detection and morphology operations.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">phenopype</span> <span class="k">as</span> <span class="nn">pp</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">filepath</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;images/isopods.jpg&quot;</span>

<span class="n">pp</span><span class="o">.</span><span class="n">pype</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;iso1&quot;</span><span class="p">,</span> <span class="n">config_preset</span><span class="o">=</span><span class="s2">&quot;object_detection_morph&quot;</span><span class="p">,</span> <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;../_temp/output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


------------+++ new pype iteration 2020:04:11 14:25:24 +++--------------


SEGMENTATION
blur
threshold
morphology
find_contours
VISUALIZATION
select_canvas
- invalid selection - defaulting to raw image
draw_contours
EXPORT
save_contours
- contours saved under ../_temp/output\contours_iso1.csv (overwritten).
AUTOSAVE
save_canvas
- canvas saved under ../_temp/output\canvas_iso1.jpg (overwritten).


TERMINATE
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[28]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;phenopype.main.pype at 0x165f3a4ec48&gt;
</pre></div></div>
</div>
<p>If course, this default template does not come with the settings we have laboriously determined in the steps above - so we need to modify the settings in the configuration file. You can do so by simply changing according to our previous settings. For example:</p>
<p><code class="docutils literal notranslate"><span class="pre">pp.segmentation.threshold(ct,</span> <span class="pre">method=&quot;adaptive&quot;,</span> <span class="pre">blocksize=49,</span> <span class="pre">constant=5,</span> <span class="pre">channel=&quot;green&quot;)</span></code></p>
<p>becomes</p>
<p><code class="docutils literal notranslate"><span class="pre">-</span> <span class="pre">threshold:</span>&#160;&#160;&#160;&#160; <span class="pre">method:</span> <span class="pre">adaptive</span>&#160;&#160;&#160;&#160; <span class="pre">blocksize:</span> <span class="pre">49</span>&#160;&#160;&#160;&#160; <span class="pre">constant:</span> <span class="pre">5</span>&#160;&#160;&#160;&#160; <span class="pre">channel:</span> <span class="pre">green</span></code></p>
<p>Read more on how yaml-syntax works in the <a class="reference internal" href="tutorial_2_phenopype_workflow.html#yaml-syntax"><span class="std std-ref">corresponding section in Tutorial 2</span></a></p>
<p>For convenience, the appropriate settings for this example are contained in a preset template named <code class="docutils literal notranslate"><span class="pre">demo2</span></code>, which we can supply directly to the <code class="docutils literal notranslate"><span class="pre">pype</span></code>. Note that we need to rename this run, otherwise the <code class="docutils literal notranslate"><span class="pre">pype</span></code> will reload our old settings (you can also just delete them in the folder).</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[29]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">pp</span><span class="o">.</span><span class="n">presets</span><span class="o">.</span><span class="n">demo2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

preprocessing:
- create_mask
- create_scale:
    mask: true
segmentation:
- blur:
    kernel_size: 15
- threshold:
    method: adaptive
    blocksize: 49
    constant: 5
    channel: green
- morphology:
    operation: open
    shape: cross
    kernel_size: 9
    iterations: 2
- find_contours:
    retrieval: ccomp
    min_diameter: 0
    min_area: 250
visualization:
- select_canvas:
    canvas: image
- draw_contours:
    line_width: 2
    label_width: 1
    label_size: 1
    fill: 0.3
export:
- save_contours:
    overwrite: true

</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">pp</span><span class="o">.</span><span class="n">pype</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;iso2&quot;</span><span class="p">,</span> <span class="n">config_preset</span><span class="o">=</span><span class="s2">&quot;demo2&quot;</span><span class="p">,</span> <span class="n">dirpath</span><span class="o">=</span><span class="sa">r</span><span class="s2">&quot;../_temp/output&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>


------------+++ new pype iteration 2020:04:11 14:25:31 +++--------------


AUTOLOAD
- masks_iso2.csv
PREPROCESSING
create_mask
- mask with label mask1 already created (overwrite=False)
create_scale
- measure pixel-to-mm-ratio
Scale set
- add column length
Template selected
- scale template mask already created (overwrite=False)
SEGMENTATION
blur
threshold
- applying mask: mask1
- applying mask: scale
morphology
find_contours
VISUALIZATION
select_canvas
- invalid selection - defaulting to raw image
draw_contours
EXPORT
save_contours
- contours saved under ../_temp/output\contours_iso2.csv (overwritten).
AUTOSAVE
save_canvas
- canvas saved under ../_temp/output\canvas_iso2.jpg (overwritten).
save_masks
- masks not saved - file already exists (overwrite=False).


TERMINATE
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[30]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;phenopype.main.pype at 0x165816af348&gt;
</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2020, Moritz Lürig.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.4.4.<br/>
    </p>
  </div>
</footer>
  </body>
</html>